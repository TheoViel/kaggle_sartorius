{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from utils.logger import Config, save_to_folder\n",
    "from utils.rle import rle_encode, rle_decode\n",
    "\n",
    "from inference.tweaking import *\n",
    "from inference.validation import *\n",
    "from inference.post_process import *\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.validation import inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single xp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "\n",
    "pipelines = define_pipelines(\"configs/config_aug.py\")\n",
    "dataset = SartoriusDataset(df, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(OUT_PATH + \"ens_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = OUT_PATH + \"ens_8/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = OUT_PATH + \"ens_12/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    id_ = df['id'][i]\n",
    "\n",
    "    preds_mask = np.load(EXP_FOLDER + f\"masks_{id_}.npy\")\n",
    "    preds_boxes = np.load(EXP_FOLDER + f\"boxes_{id_}.npy\")\n",
    "    \n",
    "    results.append((preds_boxes, preds_mask))\n",
    "    \n",
    "# if EXP_FOLDER == OUT_PATH + \"ens_8/\":\n",
    "#     results = [(r[1], r[0]) for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.05, 0.1, 0.15]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(4, 17)]\n",
    "\n",
    "min_sizes = [0, 50, 100, 150]\n",
    "# min_sizes = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.15]\n",
    "thresholds_conf = [0.65]\n",
    "\n",
    "min_sizes = [0]\n",
    "# min_sizes = [35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_tweak, all_cell_types = tweak_thresholds(\n",
    "    results,\n",
    "    dataset,\n",
    "    thresholds_mask,\n",
    "    thresholds_nms,\n",
    "    thresholds_conf,\n",
    "    min_sizes=min_sizes,\n",
    "    remove_overlap=True,\n",
    "    corrupt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, best_min_sizes = [], [], [], []\n",
    "best_scores = []\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    print(f' -> Cell type {CELL_TYPES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(-2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (\n",
    "        thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[3]], min_sizes[idx[2]]\n",
    "    )\n",
    "    best_thresholds_mask.append(best_thresholds_c[0])\n",
    "    best_thresholds_nms.append(best_thresholds_c[1])\n",
    "    best_thresholds_conf.append(best_thresholds_c[2])\n",
    "    best_min_sizes.append(best_thresholds_c[3])\n",
    "\n",
    "    print(\n",
    "        f\"Best score {best_score:.4f} for thresholds (mask, nms, conf, min_size): {best_thresholds_c}\\n\"\n",
    "    )\n",
    "\n",
    "# weights = [Counter(df_oof['cell_type'])[c] for c in CELL_TYPES]\n",
    "weights = [Counter(all_cell_types)[c] for c in range(len(CELL_TYPES))]\n",
    "\n",
    "best_score = np.average(best_scores, weights=weights)\n",
    "\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, best_min_sizes = [], [], [], []\n",
    "best_scores = []\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    print(f' -> Cell type {CELL_TYPES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(-2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (\n",
    "        thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[3]], min_sizes[idx[2]]\n",
    "    )\n",
    "    best_thresholds_mask.append(best_thresholds_c[0])\n",
    "    best_thresholds_nms.append(best_thresholds_c[1])\n",
    "    best_thresholds_conf.append(best_thresholds_c[2])\n",
    "    best_min_sizes.append(best_thresholds_c[3])\n",
    "\n",
    "    print(\n",
    "        f\"Best score {best_score:.4f} for thresholds (mask, nms, conf, min_size): {best_thresholds_c}\\n\"\n",
    "    )\n",
    "\n",
    "# weights = [Counter(df_oof['cell_type'])[c] for c in CELL_TYPES]\n",
    "weights = [Counter(all_cell_types)[c] for c in range(len(CELL_TYPES))]\n",
    "\n",
    "best_score = np.average(best_scores, weights=weights)\n",
    "\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask = 0.45\n",
    "best_thresholds_nms = [0.1, 0.1, 0.15]\n",
    "best_thresholds_conf = [0.35, 0.45, 0.7]\n",
    "best_min_sizes = [0, 150, 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata = []\n",
    "all_scores = [[], [], []]\n",
    "\n",
    "masks_pred, boxes_pred, cell_types = process_results(\n",
    "    results,\n",
    "    best_thresholds_mask,\n",
    "    best_thresholds_nms,\n",
    "    best_thresholds_conf,\n",
    "    best_min_sizes,\n",
    "    remove_overlap=True,\n",
    "    corrupt=True\n",
    ")\n",
    "\n",
    "scores, scores_per_class = evaluate(\n",
    "    masks_pred,\n",
    "    dataset,\n",
    "    cell_types\n",
    ")\n",
    "\n",
    "for masks, boxes, cell_type_pred, img_id, score, cell_type in zip(\n",
    "    masks_pred, boxes_pred, cell_types, dataset.df['id'].values, scores, dataset.df['cell_type'].values\n",
    "):\n",
    "    metadata.append({\n",
    "        'id': img_id,\n",
    "        'cell_type': cell_type,\n",
    "        'cell_type_pred': cell_type_pred,\n",
    "        'rles': [rle_encode(mask) for mask in masks],\n",
    "        'boxes': boxes.tolist(),\n",
    "        'score': score\n",
    "    })\n",
    "\n",
    "for i, s in enumerate(scores_per_class):\n",
    "    all_scores[i] += s\n",
    "    \n",
    "df_preds_oof = pd.DataFrame.from_dict(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several Exps (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERS = [\n",
    "    OUT_PATH + \"ens_7/\",\n",
    "    OUT_PATH + \"ens_8/\",\n",
    "    OUT_PATH + \"ens_12/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF = [\n",
    "    [0.35, 0.45, 0.65],\n",
    "    [0.3, 0.4, 0.65],\n",
    "    [0.35, 0.4, 0.7]\n",
    "]\n",
    "THRESHOLDS_NMS = [\n",
    "    [0.1, 0.1, 0.05],\n",
    "    [0.1, 0.1, 0.15],\n",
    "    [0.1, 0.05, 0.05],\n",
    "]\n",
    "THRESHOLDS_MASK = [0.45, 0.45, 0.45]\n",
    "\n",
    "MIN_SIZES = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF_ENS = [0.3, 0.4, 0.65]\n",
    "THRESHOLDS_NMS_ENS = [0.1, 0.1, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "\n",
    "pipelines = define_pipelines(\"configs/config_aug.py\")\n",
    "\n",
    "dataset = SartoriusDataset(df, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_masks(boxes, masks, thresholds_mask, thresholds_nms, thresholds_conf, min_sizes, remove_overlap=True, corrupt=False):\n",
    "    # Cell type\n",
    "    cell = np.argmax(np.bincount(boxes[:, 5].astype(int)))\n",
    "\n",
    "    # Thresholds\n",
    "    thresh_mask = (\n",
    "        thresholds_mask if isinstance(thresholds_mask, (float, int))\n",
    "        else thresholds_mask[cell]\n",
    "    )\n",
    "    thresh_nms = (\n",
    "        thresholds_nms if isinstance(thresholds_nms, (float, int))\n",
    "        else thresholds_nms[cell]\n",
    "    )\n",
    "    thresh_conf = (\n",
    "        thresholds_conf if isinstance(thresholds_conf, (float, int))\n",
    "        else thresholds_conf[cell]\n",
    "    )\n",
    "    min_size = (\n",
    "        min_sizes if isinstance(min_sizes, (float, int))\n",
    "        else min_sizes[cell]\n",
    "    )\n",
    "\n",
    "    # Binarize\n",
    "    if thresh_mask is not None:\n",
    "        masks = masks > (thresh_mask * 255)\n",
    "\n",
    "    # Sort by decreasing conf\n",
    "    order = np.argsort(boxes[:, 4])[::-1]\n",
    "    masks = masks[order]\n",
    "    boxes = boxes[order]\n",
    "\n",
    "    # Remove low confidence\n",
    "    last = (\n",
    "        np.argmax(boxes[:, 4] < thresh_conf) if np.min(boxes[:, 4]) < thresh_conf\n",
    "        else len(boxes)\n",
    "    )\n",
    "    masks = masks[:last]\n",
    "    boxes = boxes[:last]\n",
    "\n",
    "    # NMS\n",
    "    if thresh_nms > 0:\n",
    "        masks, boxes, _ = mask_nms(masks, boxes, thresh_nms)\n",
    "        \n",
    "    # Remove small masks\n",
    "    masks, boxes = remove_small_masks(masks, boxes, min_size=min_size)\n",
    "    \n",
    "    # Corrupt\n",
    "    if corrupt and cell == 1:  # astro\n",
    "        masks = np.array([corrupt_mask(mask)[0] for mask in masks])\n",
    "\n",
    "    # Remove overlap\n",
    "    if remove_overlap:\n",
    "        masks = remove_overlap_naive(masks)\n",
    "\n",
    "    return masks, boxes, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.wsf import weighted_boxes_fusion_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(boxes, shape=ORIG_SIZE):\n",
    "    boxes = boxes.copy()\n",
    "    boxes[:, 0] /= ORIG_SIZE[1]\n",
    "    boxes[:, 1] /= ORIG_SIZE[0]\n",
    "    \n",
    "    boxes[:, 2] /= ORIG_SIZE[1]\n",
    "    boxes[:, 3] /= ORIG_SIZE[0]\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize(boxes, shape=ORIG_SIZE):\n",
    "    boxes = boxes.copy()\n",
    "    boxes[:, 0] *= ORIG_SIZE[1]\n",
    "    boxes[:, 1] *= ORIG_SIZE[0]\n",
    "    \n",
    "    boxes[:, 2] *= ORIG_SIZE[1]\n",
    "    boxes[:, 3] *= ORIG_SIZE[0]\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_key(bbox):\n",
    "    return str(np.round(bbox[:4], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse masks that belong to fused boxes\n",
    "def get_wsf_mask(wbf_box, wbf_org, pmasks, pmasks_lkup, thres=0.5):\n",
    "    \n",
    "    w, h = 520, 704\n",
    "    mask = np.zeros((w, h), dtype=np.uint8)\n",
    "\n",
    "    for i in range(len(wbf_org)):\n",
    "        key = bbox_to_key(list(wbf_org[i][4:]))\n",
    "        model = int(wbf_org[i][3])\n",
    "        \n",
    "        try:\n",
    "            ind = pmasks_lkup[model][key]\n",
    "        except KeyError:\n",
    "            print(key)\n",
    "            print(pmasks_lkup[model])\n",
    "        mask = mask + pmasks[model][ind]\n",
    "\n",
    "        \n",
    "    # convert thres to integer based on number of boxes\n",
    "    threshold = thres * len(wbf_org)\n",
    "    mask = mask > threshold\n",
    "    \n",
    "\n",
    "    # remove pixels outside WBF box\n",
    "    m2 = np.zeros((w, h), dtype=np.uint8)\n",
    "    x1 = max(0, int(h * wbf_box[0]))\n",
    "    y1 = max(0, int(w * wbf_box[1]))\n",
    "    x2 = min(h, int(h * wbf_box[2]))\n",
    "    y2 = min(w, int(w * wbf_box[3]))\n",
    "    m2[y1:y2, x1:x2] = 1\n",
    "#     mask = mask * m2\n",
    "\n",
    "    return mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsf_fct(boxes, masks, thres=0.5):\n",
    "    boxes = [normalize(b) for b in boxes]\n",
    "    \n",
    "    mappings = [{bbox_to_key(list(b)): i for i, b in enumerate(bs)} for bs in boxes]\n",
    "\n",
    "    cells = [np.argmax(np.bincount(b[:, 5].astype(int))) for b in boxes]\n",
    "    cell = np.argmax(np.bincount(cells))\n",
    "\n",
    "    # weighted boxes fusion\n",
    "    wbf_boxes, wbf_scores, _, wbf_originals = weighted_boxes_fusion_tracking(\n",
    "        [b[:, :4] for b in boxes],\n",
    "        [b[:, 4] for b in boxes],\n",
    "        labels_list=[np.ones(len(b)) for b in boxes],\n",
    "        iou_thr=0.55,\n",
    "#         skip_box_thr=THRESHOLDS[pred_class],\n",
    "    )\n",
    "    wbf_boxes = np.concatenate([wbf_boxes, wbf_scores[:, None], cell * np.ones((len(wbf_boxes), 1))], -1)\n",
    "    \n",
    "    # Finally, process masks, making sure there is no overlap\n",
    "#     res = []\n",
    "#     used = np.zeros(ORIG_SIZE, dtype=int)\n",
    "    \n",
    "#     pred_label = CLASS_LABELS[pred_class + 1]\n",
    "#     min_key = pred_label + \" min\"\n",
    "#     major_axis_len_min = cell_df[cell_df.feature == \"major_axis_len\"][min_key].iloc[0]\n",
    "    # process\n",
    "    new_masks, new_boxes = [], []\n",
    "    for i in range(len(wbf_boxes)):\n",
    "        \n",
    "        if len(wbf_originals[i]) < 1:\n",
    "#             print('skip')\n",
    "            continue\n",
    "\n",
    "        mask = get_wsf_mask(\n",
    "            wbf_boxes[i], wbf_originals[i], masks, mappings, thres=0.\n",
    "        )\n",
    "        \n",
    "#         plt.imshow(mask)\n",
    "\n",
    "        # get shape properties\n",
    "        props = measure.regionprops(mask)\n",
    "\n",
    "        # if there are multiple separated masks, pick the larger one\n",
    "        areas = []\n",
    "        for a in range(len(props)):\n",
    "            areas.append(props[a].area)\n",
    "        try:\n",
    "            target = np.argmax(areas)\n",
    "        except:\n",
    "            continue\n",
    "        # extract properties of interest\n",
    "        major_axis_len = props[target].major_axis_length\n",
    "        # check against limits\n",
    "        if major_axis_len >= major_axis_len_min:\n",
    "            mask = mask * (1 - used)\n",
    "            # check if mask is chopped up by previous detections\n",
    "            if len(measure.find_contours(mask, 0.5, positive_orientation=\"low\")) == 1:\n",
    "                used += mask\n",
    "                res.append(rle_encode(mask))\n",
    "        print(wbf_boxes)\n",
    "\n",
    "        new_masks.append(mask)\n",
    "        new_boxes.append(wbf_boxes[i])\n",
    "        \n",
    "#         break\n",
    "        \n",
    "    return np.array(new_boxes), np.array(new_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = {0: [], 1: [], 2: [], \"ens\": []}\n",
    "N = 50\n",
    "\n",
    "for i in tqdm(range(len(df.head(N)))):\n",
    "#     i = 2\n",
    "    id_ = df['id'][i]\n",
    "\n",
    "    preds_mask = [np.load(f + f\"masks_{id_}.npy\") for f in FOLDERS]\n",
    "    preds_boxes = [np.load(f + f\"boxes_{id_}.npy\") for f in FOLDERS]\n",
    "    \n",
    "    data = dataset[i]\n",
    "    img = data['img']\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "#     boxes_truth = data['gt_bboxes']\n",
    "    rle_truth = dataset.encodings[i].tolist()\n",
    "\n",
    "    bs = []\n",
    "    ms = []\n",
    "    rles = []\n",
    "    \n",
    "    for i, (m, b) in enumerate(zip(preds_mask, preds_boxes)):\n",
    "        if m.shape[-1] == 6:\n",
    "            b, m = m, b  # swap\n",
    "\n",
    "        masks, boxes, cell  = process_masks(\n",
    "            b.copy(), m.copy(), THRESHOLDS_MASK, THRESHOLDS_NMS[i], THRESHOLDS_CONF[i], MIN_SIZES, remove_overlap=True, corrupt=False\n",
    "        )\n",
    "\n",
    "        rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks]\n",
    "        iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "        score = iou_map(ious=[iou], verbose=0)\n",
    "\n",
    "        bs.append(boxes)\n",
    "        ms.append(masks)\n",
    "        scores[i].append(score)\n",
    "\n",
    "#         bs.append(b)\n",
    "#         ms.append(m)\n",
    "        rles.append(rle_pred)\n",
    "        \n",
    "        print(f' -> IoU mAP #{i}: {score:.4f}')\n",
    "\n",
    "#         plt.figure(figsize=(15, 10))\n",
    "#         plot_sample(img, mask=masks.astype(int), boxes=boxes)\n",
    "#         plt.axis(False)\n",
    "#         plt.show()\n",
    "    \n",
    "    boxes_m, masks_m = wsf_fct(bs, ms)\n",
    "        \n",
    "    masks_m, boxes_m, cell  = process_masks(\n",
    "        boxes_m, masks_m, 0., THRESHOLDS_NMS_ENS, THRESHOLDS_CONF_ENS, MIN_SIZES, remove_overlap=True, corrupt=False\n",
    "    )\n",
    "\n",
    "    rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks_m]\n",
    "    iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "    score = iou_map(ious=[iou], verbose=0)\n",
    "    scores['ens'].append(score)\n",
    "\n",
    "    print(f' -> IoU mAP ens: {score:.4f}\\n')\n",
    "\n",
    "#     plt.figure(figsize=(15, 10))\n",
    "#     plot_sample(img, mask=masks_m.astype(int), boxes=boxes_m)\n",
    "#     plt.axis(False)\n",
    "#     plt.show()\n",
    "        \n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df.copy().head(N)\n",
    "dfp['scores_0'] = scores[0]\n",
    "dfp['scores_1'] = scores[1]\n",
    "dfp['scores_2'] = scores[2]\n",
    "dfp['scores_ens'] = scores[\"ens\"]\n",
    "\n",
    "dfp[['cell_type', 'scores_0', 'scores_1', 'scores_2', 'scores_ens']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "#     ms[0].astype(int),\n",
    "    masks_m.astype(int),\n",
    "    truth,\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "    ms[0].astype(int),\n",
    "#     masks_m.astype(int),\n",
    "    truth,\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SIZE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF = [\n",
    "#     [0.35, 0.45, 0.65],\n",
    "    [0.3, 0.4, 0.65],\n",
    "#     [0.35, 0.4, 0.7]\n",
    "]\n",
    "THRESHOLDS_NMS = [\n",
    "#     [0.1, 0.1, 0.05],\n",
    "    [0.1, 0.1, 0.15],\n",
    "#     [0.1, 0.05, 0.05],\n",
    "]\n",
    "THRESHOLDS_MASK = [0.45, 0.45, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in tqdm(range(len(df))[:30]):\n",
    "    id_ = df['id'][i]\n",
    "\n",
    "    preds_mask = [np.load(f + f\"masks_{id_}.npy\") for f in FOLDERS]\n",
    "    preds_boxes = [np.load(f + f\"boxes_{id_}.npy\") for f in FOLDERS]\n",
    "    \n",
    "#     data = dataset[i]\n",
    "#     img = data['img']\n",
    "#     truth = data['gt_masks'].masks.copy().astype(int)\n",
    "#     boxes_truth = data['gt_bboxes']\n",
    "    rle_truth = dataset.encodings[i].tolist()\n",
    "\n",
    "    bs = []\n",
    "    ms = []\n",
    "    rles = []\n",
    "    \n",
    "    for i, (m, b) in enumerate(zip(preds_mask, preds_boxes)):\n",
    "        if m.shape[-1] == 6:\n",
    "            b, m = m, b  # swap\n",
    "            \n",
    "        masks, boxes, cell  = process_masks(\n",
    "            b, m, THRESHOLDS_MASK, THRESHOLDS_NMS[i], THRESHOLDS_CONF[i], remove_overlap=True, corrupt=True\n",
    "        )\n",
    "        \n",
    "#         masks = [m for m in masks if m.sum() > MIN_SIZE]\n",
    "\n",
    "        rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks]\n",
    "        iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "        score = iou_map(ious=[iou])\n",
    "        \n",
    "        scores.append(score)\n",
    "        bs.append(boxes)\n",
    "        ms.append(masks)\n",
    "\n",
    "#         bs.append(b)\n",
    "#         ms.append(m)\n",
    "        \n",
    "#     boxes_m, masks_m = merge_preds_vote(bs, ms)\n",
    "        \n",
    "#     masks_m, boxes_m, cell  = process_masks(\n",
    "#         boxes_m, masks_m, 0., THRESHOLDS_NMS_ENS, THRESHOLDS_CONF_ENS, remove_overlap=True, corrupt=True\n",
    "#     )\n",
    "\n",
    "#     rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks_m]\n",
    "#     iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "#     score = iou_map(ious=[iou])\n",
    "\n",
    "#     scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_oof = df.copy().head(len(scores))  # 0\n",
    "df_preds_oof['score'] = scores\n",
    "\n",
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cort : 75\n",
    "astro : 125\n",
    "shsy5y : 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
