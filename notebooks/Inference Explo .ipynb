{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from utils.logger import Config, save_to_folder\n",
    "from utils.rle import rle_encode, rle_decode\n",
    "\n",
    "from inference.tweaking import *\n",
    "from inference.validation import *\n",
    "from inference.post_process import *\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.validation import inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single xp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "\n",
    "pipelines = define_pipelines(\"configs/config_aug.py\")\n",
    "dataset = SartoriusDataset(df, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = OUT_PATH + \"ens_8/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.05, 0.1, 0.15]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(4, 17)]\n",
    "\n",
    "min_sizes = [0, 25, 50, 75, 100, 125, 150]\n",
    "# min_sizes = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.15]\n",
    "thresholds_conf = [0.65]\n",
    "\n",
    "min_sizes = [75]\n",
    "# min_sizes = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    id_ = df['id'][i]\n",
    "\n",
    "    preds_mask = np.load(EXP_FOLDER + f\"masks_{id_}.npy\")\n",
    "    preds_boxes = np.load(EXP_FOLDER + f\"boxes_{id_}.npy\")\n",
    "    \n",
    "    results.append((preds_boxes, preds_mask))\n",
    "    \n",
    "# if EXP_FOLDER == OUT_PATH + \"ens_8/\":\n",
    "#     results = [(r[1], r[0]) for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_tweak, all_cell_types = tweak_thresholds(\n",
    "    results,\n",
    "    dataset,\n",
    "    thresholds_mask,\n",
    "    thresholds_nms,\n",
    "    thresholds_conf,\n",
    "    min_sizes=min_sizes,\n",
    "    remove_overlap=True,\n",
    "    corrupt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, best_min_sizes = [], [], [], []\n",
    "best_scores = []\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    print(f' -> Cell type {CELL_TYPES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(-2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (\n",
    "        thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[3]], min_sizes[idx[2]]\n",
    "    )\n",
    "    best_thresholds_mask.append(best_thresholds_c[0])\n",
    "    best_thresholds_nms.append(best_thresholds_c[1])\n",
    "    best_thresholds_conf.append(best_thresholds_c[2])\n",
    "    best_min_sizes.append(best_thresholds_c[3])\n",
    "\n",
    "    print(\n",
    "        f\"Best score {best_score:.4f} for thresholds (mask, nms, conf, min_size): {best_thresholds_c}\\n\"\n",
    "    )\n",
    "\n",
    "# weights = [Counter(df_oof['cell_type'])[c] for c in CELL_TYPES]\n",
    "weights = [Counter(all_cell_types)[c] for c in range(len(CELL_TYPES))]\n",
    "\n",
    "best_score = np.average(best_scores, weights=weights)\n",
    "\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "all_scores = [[], [], []]\n",
    "\n",
    "masks_pred, boxes_pred, cell_types = process_results(\n",
    "    results,\n",
    "    best_thresholds_mask,\n",
    "    best_thresholds_nms,\n",
    "    best_thresholds_conf,\n",
    "    best_min_sizes,\n",
    "    remove_overlap=True,\n",
    "    corrupt=True\n",
    ")\n",
    "\n",
    "scores, scores_per_class = evaluate(\n",
    "    masks_pred,\n",
    "    dataset,\n",
    "    cell_types\n",
    ")\n",
    "\n",
    "for masks, boxes, cell_type_pred, img_id, score, cell_type in zip(\n",
    "    masks_pred, boxes_pred, cell_types, dataset.df['id'].values, scores, dataset.df['cell_type'].values\n",
    "):\n",
    "    metadata.append({\n",
    "        'id': img_id,\n",
    "        'cell_type': cell_type,\n",
    "        'cell_type_pred': cell_type_pred,\n",
    "        'rles': [rle_encode(mask) for mask in masks],\n",
    "        'boxes': boxes.tolist(),\n",
    "        'score': score\n",
    "    })\n",
    "\n",
    "for i, s in enumerate(scores_per_class):\n",
    "    all_scores[i] += s\n",
    "    \n",
    "df_preds_oof = pd.DataFrame.from_dict(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')  # [1000, 8000, 1000]\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several Exps (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERS = [\n",
    "#     OUT_PATH + \"ens_7/\",\n",
    "    OUT_PATH + \"ens_8/\",\n",
    "#     OUT_PATH + \"ens_12/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF = [\n",
    "#     [0.35, 0.45, 0.65],\n",
    "    [0.3, 0.4, 0.65],\n",
    "#     [0.35, 0.4, 0.7]\n",
    "]\n",
    "THRESHOLDS_NMS = [\n",
    "#     [0.1, 0.1, 0.05],\n",
    "    [0.1, 0.1, 0.15],\n",
    "#     [0.1, 0.05, 0.05],\n",
    "]\n",
    "THRESHOLDS_MASK = [0.45, 0.45, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF_ENS = [0.3, 0.4, 0.65]\n",
    "THRESHOLDS_NMS_ENS = [0.1, 0.1, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "\n",
    "pipelines = define_pipelines(\"configs/config_aug.py\")\n",
    "\n",
    "dataset = SartoriusDataset(df, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_masks(boxes, masks, thresholds_mask, thresholds_nms, thresholds_conf, min_sizes, remove_overlap=True, corrupt=False):\n",
    "    # Cell type\n",
    "    cell = np.argmax(np.bincount(boxes[:, 5].astype(int)))\n",
    "\n",
    "    # Thresholds\n",
    "    thresh_mask = (\n",
    "        thresholds_mask if isinstance(thresholds_mask, (float, int))\n",
    "        else thresholds_mask[cell]\n",
    "    )\n",
    "    thresh_nms = (\n",
    "        thresholds_nms if isinstance(thresholds_nms, (float, int))\n",
    "        else thresholds_nms[cell]\n",
    "    )\n",
    "    thresh_conf = (\n",
    "        thresholds_conf if isinstance(thresholds_conf, (float, int))\n",
    "        else thresholds_conf[cell]\n",
    "    )\n",
    "    min_size = (\n",
    "        min_size if isinstance(min_size, (float, int))\n",
    "        else min_sizes[cell]\n",
    "    )\n",
    "\n",
    "    # Binarize\n",
    "    if thresh_mask is not None:\n",
    "        masks = masks > (thresh_mask * 255)\n",
    "\n",
    "    # Sort by decreasing conf\n",
    "    order = np.argsort(boxes[:, 4])[::-1]\n",
    "    masks = masks[order]\n",
    "    boxes = boxes[order]\n",
    "\n",
    "    # Remove low confidence\n",
    "    last = (\n",
    "        np.argmax(boxes[:, 4] < thresh_conf) if np.min(boxes[:, 4]) < thresh_conf\n",
    "        else len(boxes)\n",
    "    )\n",
    "    masks = masks[:last]\n",
    "    boxes = boxes[:last]\n",
    "\n",
    "    # NMS\n",
    "    if thresh_nms > 0:\n",
    "        masks, boxes, _ = mask_nms(masks, boxes, thresh_nms)\n",
    "        \n",
    "    # Remove small masks\n",
    "    masks, boxes = remove_small_masks(masks, boxes, min_size=min_size)\n",
    "    \n",
    "    # Corrupt\n",
    "    if corrupt and cell == 1:  # astro\n",
    "        masks = np.array([corrupt_mask(mask)[0] for mask in masks])\n",
    "\n",
    "    # Remove overlap\n",
    "    if remove_overlap:\n",
    "        masks = remove_overlap_naive(masks)\n",
    "\n",
    "    return masks, boxes, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_union(boxes, masks):\n",
    "    boxes = np.concatenate(boxes)\n",
    "    masks = np.concatenate(masks)\n",
    "\n",
    "    order = np.argsort(boxes[:, 4])[::-1]\n",
    "    masks = masks[order]\n",
    "    boxes = boxes[order]\n",
    "\n",
    "    return boxes, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_preds_vote(boxes, masks):\n",
    "    assert len(boxes) == 3\n",
    "    \n",
    "    rles = [[pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks_] for masks_ in masks]\n",
    "    \n",
    "    ious_01 = pycocotools.mask.iou(rles[0], rles[1], [0] * 10000)\n",
    "    ious_12 = pycocotools.mask.iou(rles[1], rles[2], [0] * 10000)\n",
    "    ious_02 = pycocotools.mask.iou(rles[0], rles[2], [0] * 10000)\n",
    "\n",
    "    matched_01 = ious_01.max(1) > 0.75\n",
    "    matched_10 = ious_01.max(0) > 0.75\n",
    "\n",
    "    matched_02 = ious_02.max(1) > 0.75\n",
    "    matched_20 = ious_02.max(0) > 0.75\n",
    "    \n",
    "    matched_12 = ious_12.max(1) > 0.75\n",
    "    matched_21 = ious_12.max(0) > 0.75\n",
    "    \n",
    "    to_keep_0 = matched_01 + matched_02\n",
    "    to_keep_1 = matched_10 + matched_12\n",
    "    to_keep_2 = matched_20 + matched_21\n",
    "    \n",
    "    new_boxes = [\n",
    "        boxes[0][to_keep_0],\n",
    "        boxes[1][to_keep_1],\n",
    "        boxes[2][to_keep_2],\n",
    "    ]\n",
    "    \n",
    "    new_masks = [\n",
    "        masks[0][to_keep_0],\n",
    "        masks[1][to_keep_1],\n",
    "        masks[2][to_keep_2],\n",
    "    ]\n",
    "    \n",
    "    new_boxes = np.concatenate(new_boxes)\n",
    "    new_masks = np.concatenate(new_masks)\n",
    "\n",
    "    return new_boxes, new_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    i = 2\n",
    "    id_ = df['id'][i]\n",
    "\n",
    "    preds_mask = [np.load(f + f\"masks_{id_}.npy\") for f in FOLDERS]\n",
    "    preds_boxes = [np.load(f + f\"boxes_{id_}.npy\") for f in FOLDERS]\n",
    "    \n",
    "    data = dataset[i]\n",
    "    img = data['img']\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "#     boxes_truth = data['gt_bboxes']\n",
    "    rle_truth = dataset.encodings[i].tolist()\n",
    "\n",
    "    bs = []\n",
    "    ms = []\n",
    "    rles = []\n",
    "    \n",
    "    for i, (m, b) in enumerate(zip(preds_mask, preds_boxes)):\n",
    "        if m.shape[-1] == 6:\n",
    "            b, m = m, b  # swap\n",
    "\n",
    "        masks, boxes, cell  = process_masks(\n",
    "            b.copy(), m.copy(), THRESHOLDS_MASK, THRESHOLDS_NMS[i], THRESHOLDS_CONF[i], remove_overlap=True, corrupt=False\n",
    "        )\n",
    "\n",
    "        rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks]\n",
    "        iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "        score = iou_map(ious=[iou])\n",
    "\n",
    "        bs.append(boxes)\n",
    "        ms.append(masks)\n",
    "        scores.append(score)\n",
    "\n",
    "#         bs.append(b)\n",
    "#         ms.append(m)\n",
    "        rles.append(rle_pred)\n",
    "        \n",
    "        print(f' -> IoU mAP : {score:.4f}\\n')\n",
    "\n",
    "#         plt.figure(figsize=(15, 10))\n",
    "#         plot_sample(img, mask=masks.astype(int), boxes=boxes)\n",
    "#         plt.axis(False)\n",
    "#         plt.show()\n",
    "    \n",
    "    boxes_m, masks_m = merge_preds_vote(bs, ms)\n",
    "    \n",
    "    print(boxes_m.shape, masks_m.shape)\n",
    "        \n",
    "    masks_m, boxes_m, cell  = process_masks(\n",
    "        boxes_m, masks_m, 0., THRESHOLDS_NMS_ENS, THRESHOLDS_CONF_ENS, remove_overlap=False, corrupt=False\n",
    "    )\n",
    "    print(masks_m.shape)\n",
    "\n",
    "    rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks_m]\n",
    "    iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "    score = iou_map(ious=[iou])\n",
    "\n",
    "    print(f' -> IoU mAP : {score:.4f}\\n')\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plot_sample(img, mask=masks_m.astype(int), boxes=boxes_m)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "        \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "#     ms[0].astype(int),\n",
    "    masks_m.astype(int),\n",
    "    truth,\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SIZE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF = [\n",
    "#     [0.35, 0.45, 0.65],\n",
    "    [0.3, 0.4, 0.65],\n",
    "#     [0.35, 0.4, 0.7]\n",
    "]\n",
    "THRESHOLDS_NMS = [\n",
    "#     [0.1, 0.1, 0.05],\n",
    "    [0.1, 0.1, 0.15],\n",
    "#     [0.1, 0.05, 0.05],\n",
    "]\n",
    "THRESHOLDS_MASK = [0.45, 0.45, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in tqdm(range(len(df))[:30]):\n",
    "    id_ = df['id'][i]\n",
    "\n",
    "    preds_mask = [np.load(f + f\"masks_{id_}.npy\") for f in FOLDERS]\n",
    "    preds_boxes = [np.load(f + f\"boxes_{id_}.npy\") for f in FOLDERS]\n",
    "    \n",
    "#     data = dataset[i]\n",
    "#     img = data['img']\n",
    "#     truth = data['gt_masks'].masks.copy().astype(int)\n",
    "#     boxes_truth = data['gt_bboxes']\n",
    "    rle_truth = dataset.encodings[i].tolist()\n",
    "\n",
    "    bs = []\n",
    "    ms = []\n",
    "    rles = []\n",
    "    \n",
    "    for i, (m, b) in enumerate(zip(preds_mask, preds_boxes)):\n",
    "        if m.shape[-1] == 6:\n",
    "            b, m = m, b  # swap\n",
    "            \n",
    "        masks, boxes, cell  = process_masks(\n",
    "            b, m, THRESHOLDS_MASK, THRESHOLDS_NMS[i], THRESHOLDS_CONF[i], remove_overlap=True, corrupt=True\n",
    "        )\n",
    "        \n",
    "#         masks = [m for m in masks if m.sum() > MIN_SIZE]\n",
    "\n",
    "        rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks]\n",
    "        iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "        score = iou_map(ious=[iou])\n",
    "        \n",
    "        scores.append(score)\n",
    "        bs.append(boxes)\n",
    "        ms.append(masks)\n",
    "\n",
    "#         bs.append(b)\n",
    "#         ms.append(m)\n",
    "        \n",
    "#     boxes_m, masks_m = merge_preds_vote(bs, ms)\n",
    "        \n",
    "#     masks_m, boxes_m, cell  = process_masks(\n",
    "#         boxes_m, masks_m, 0., THRESHOLDS_NMS_ENS, THRESHOLDS_CONF_ENS, remove_overlap=True, corrupt=True\n",
    "#     )\n",
    "\n",
    "#     rle_pred = [pycocotools.mask.encode(np.asarray(p, order='F')) for p in masks_m]\n",
    "#     iou = pycocotools.mask.iou(rle_truth, rle_pred, [0] * len(rle_pred))\n",
    "#     score = iou_map(ious=[iou])\n",
    "\n",
    "#     scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds_oof = df.copy().head(len(scores))  # 0\n",
    "df_preds_oof['score'] = scores\n",
    "\n",
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cort : 75\n",
    "astro : 125\n",
    "shsy5y : 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
