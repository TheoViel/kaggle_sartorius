{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from utils.logger import Config\n",
    "from utils.rle import rle_encode, rle_decode\n",
    "\n",
    "from inference.tweaking import *\n",
    "from inference.validation import *\n",
    "from inference.post_process import *\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.validation import inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ENS_7\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3127\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_new_splits/\", # 7. maskrcnn rx101 - 0.3120\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ENS_8\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3127\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # new folds - fix tta\n",
    "#     LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "#     LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "#     LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "#     LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn r101 0.3131\n",
    "#     LOG_PATH + \"seb/mrcnn_r50_lossdecay/\",  # 12. mrcnn r50 0.3125\n",
    "#     LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 14. htc r50 - 0.3121\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [5000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.7, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.9, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],  # [1500, 1000, 500],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.7, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.25, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [3000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.75, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.95, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],  # [1500, 1000, 500],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.75, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.3, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "\n",
    "    try:\n",
    "        _ = config.split\n",
    "        remove_anomalies = config.remove_anomalies\n",
    "    except:\n",
    "        config.split = \"skf\"\n",
    "        remove_anomalies = False\n",
    "\n",
    "    configs.append(config)\n",
    "    \n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=remove_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_results, dfs_val = inference_val(df, configs, weights, ENSEMBLE_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.concat(dfs_val).reset_index(drop=True)\n",
    "df_oof['class'] = df_oof['cell_type']\n",
    "\n",
    "pipelines = define_pipelines(config.data_config)\n",
    "\n",
    "datasets = [SartoriusDataset(df_val, transforms=pipelines['val_viz'], precompute_masks=False) for df_val in dfs_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask = [0.45, 0.45, 0.45]\n",
    "best_thresholds_nms = [0.1, 0.1, 0.05]\n",
    "best_thresholds_conf = [0.3, 0.4, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES = [\n",
    "#     \"astro[hippo]\",\n",
    "#     \"astros[cereb]\",\n",
    "#     \"cort[6-OHDA_oka-low]\",\n",
    "#     \"cort[density_pre-treat]\",\n",
    "#     \"cort[oka-high_debris]\",\n",
    "#     \"shsy5y\",\n",
    "# ]\n",
    "\n",
    "# def plate_to_class(plate):\n",
    "#     mapping = {\n",
    "#         \"astro[hippo]\": 0,\n",
    "#         \"astros[cereb]\": 1,\n",
    "#         \"cort[6-OHDA]\": 2,\n",
    "#         \"cort[debris]\": 4,\n",
    "#         \"cort[density]\": 3,\n",
    "#         \"cort[oka-high]\": 4,\n",
    "#         \"cort[oka-low]\": 2,\n",
    "#         \"cort[pre-treat]\": 3,\n",
    "#         \"shsy5y[diff]\": 5,\n",
    "#     }\n",
    "#     return mapping[plate]\n",
    "\n",
    "# df_oof['class'] = df_oof['plate'].apply(plate_to_class)\n",
    "# pred_plate = np.load(\"../output/pred_plate.npy\")\n",
    "# df['pred_plate'] = pred_plate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.05, 0.1, 0.15]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(4, 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for dataset, results in zip(datasets, all_results):\n",
    "#     cell_types = dataset.df['plate'].apply(plate_to_class).values  # GT\n",
    "#     cell_types = dataset.df.merge(df, on=\"id\", how=\"left\")['pred_plate'].values  # PRED\n",
    "    cell_types = None\n",
    "\n",
    "    scores = tweak_thresholds(\n",
    "        results,\n",
    "        dataset,\n",
    "        thresholds_mask,\n",
    "        thresholds_nms,\n",
    "        thresholds_conf,\n",
    "#         num_classes=len(CLASSES),\n",
    "        remove_overlap=True,\n",
    "        corrupt=True,\n",
    "        cell_types=cell_types\n",
    "    )\n",
    "    all_scores.append(scores)\n",
    "\n",
    "if cell_types is None:\n",
    "    CLASSES = CELL_TYPES\n",
    "\n",
    "scores_tweak = [\n",
    "    np.concatenate([scores_fold[c] for scores_fold in all_scores if scores_fold[c].shape[-1]], 2)\n",
    "    for c in range(len(CLASSES)) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask, best_thresholds_nms, best_thresholds_conf = [], [], []\n",
    "best_scores = []\n",
    "\n",
    "for c in range(len(CLASSES)):\n",
    "    print(f' -> Cell type {CLASSES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[2]])\n",
    "    best_thresholds_mask.append(best_thresholds_c[0])\n",
    "    best_thresholds_nms.append(best_thresholds_c[1])\n",
    "    best_thresholds_conf.append(best_thresholds_c[2])\n",
    "\n",
    "    print(f\"Best score {best_score:.4f} for thresholds (mask, nms, conf): {best_thresholds_c}\\n\")\n",
    "\n",
    "if cell_types is None:\n",
    "    weights = [Counter(df_oof['cell_type'])[c] for c in CELL_TYPES]\n",
    "else:\n",
    "#     weights = [Counter(df_oof['class'].values)[c] for c in range(len(CLASSES))]\n",
    "    weights = [Counter(pred_plate)[c] for c in range(len(CLASSES))]\n",
    "\n",
    "best_score = np.average(best_scores, weights=weights)\n",
    "\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for c in range(len(CLASSES)):\n",
    "#     print(f\"\\nClass {CLASSES[c]}\")\n",
    "#     for idx_mask, threshold_mask in enumerate(thresholds_mask):\n",
    "#         for idx_nms, threshold_nms in enumerate(thresholds_nms):\n",
    "#             print(f\"\\n-> Threshold mask = {threshold_mask} - Threshold nms = {threshold_nms}\")\n",
    "#             for s, conf in zip(np.mean(scores_tweak[c][idx_mask, idx_nms], 0) , thresholds_conf):\n",
    "#                 print(f\"Threshold conf = {conf} - score = {s:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'THRESHOLDS_MASK = {best_thresholds_mask}')\n",
    "print(f'THRESHOLDS_NMS = {best_thresholds_nms}')\n",
    "print(f'THRESHOLDS_CONF = {best_thresholds_conf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [[], [], []]\n",
    "metadata = []\n",
    "\n",
    "for results, dataset in zip(all_results, datasets):\n",
    "    masks_pred, boxes_pred, cell_types = process_results(\n",
    "        results,\n",
    "        best_thresholds_mask,\n",
    "        best_thresholds_nms,\n",
    "        best_thresholds_conf,\n",
    "        remove_overlap=True,\n",
    "        corrupt=True\n",
    "    )\n",
    "    \n",
    "    scores, scores_per_class = evaluate(\n",
    "        masks_pred,\n",
    "        dataset,\n",
    "        cell_types\n",
    "    )\n",
    "    \n",
    "    for masks, boxes, cell, img_id, score in zip(\n",
    "        masks_pred, boxes_pred, cell_types, dataset.df['id'].values, scores\n",
    "    ):\n",
    "        metadata.append({\n",
    "            'id': img_id,\n",
    "            'rles': [rle_encode(mask) for mask in masks],\n",
    "            'boxes': boxes.tolist(),\n",
    "            'cell_type': cell,\n",
    "            'score': score\n",
    "        })\n",
    "    \n",
    "\n",
    "    for i, s in enumerate(scores_per_class):\n",
    "        all_scores[i] += s\n",
    "        \n",
    "    del masks_pred, boxes_pred, cell_types\n",
    "    gc.collect()\n",
    "\n",
    "#     break\n",
    "    \n",
    "df_preds_oof = pd.DataFrame.from_dict(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(EXP_FOLDERS) == 1:\n",
    "#     save_folder = EXP_FOLDERS[0]\n",
    "#     name = 'df_oof.csv'\n",
    "# else:\n",
    "#     save_folder = OUT_PATH\n",
    "#     name = 'df_oof_blend'\n",
    "\n",
    "#     for f in EXP_FOLDERS:\n",
    "#         name += f\"_{f.split('/')[-3][5:]}-{f.split('/')[-2]}\"\n",
    "#     name += \".csv\"\n",
    "\n",
    "# print(f'-> Saved results to \"{save_folder + name}\"')\n",
    "\n",
    "# df_preds_oof.to_csv(save_folder + name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(len(all_scores)):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.title(CELL_TYPES[i], size=15)\n",
    "    plt.grid(True)\n",
    "    plt.scatter(range(len(all_scores[i])), sorted(all_scores[i]), s=20)\n",
    "#     plt.ylim(0, 0.75)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('IoU mAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.mean(np.concatenate(all_scores))\n",
    "scores_class = [np.mean(s) for s in all_scores if len(s)]\n",
    "\n",
    "print(f' -> IoU mAP : {score:.4f}\\n')\n",
    "\n",
    "for s, c in zip(scores_class, CELL_TYPES):\n",
    "    print(f'{c} : {s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = df_oof.merge(df_preds_oof, on=\"id\", how=\"left\", suffixes=('', '_pred'))\n",
    "df_oof['n_cells'] = df_oof['annotation'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_oof.groupby('plate').mean()[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.violinplot(x='score', y='plate', data=df_oof.sort_values('plate'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof.groupby('cell_type').mean()[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_preds, masks_truth = [], []\n",
    "\n",
    "# for results, dataset in zip(all_results, datasets):\n",
    "#     masks_pred, boxes_pred, cell_types = process_results(\n",
    "#         results, best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, remove_overlap=True\n",
    "#     )\n",
    "    \n",
    "#     masks_preds.append(masks.max(0))\n",
    "    \n",
    "#     masks_truth += [masks.masks.max(0) for masks in dataset.masks]\n",
    "\n",
    "# dice_score(np.array(masks_preds), np.array(masks_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SartoriusDataset(df_oof, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(len(dataset)):\n",
    "    if df_oof['plate'][idx] != \"cort[density]\":\n",
    "        continue\n",
    "    \n",
    "    score = df_preds_oof['score'][idx]\n",
    "    c = df_preds_oof['cell_type'][idx]\n",
    "    \n",
    "    data = dataset[idx]\n",
    "    img = data['img']\n",
    "    \n",
    "    # truth\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "    boxes_truth = data['gt_bboxes']\n",
    "    \n",
    "    # preds\n",
    "    rles = df_preds_oof['rles'][idx]\n",
    "    pred = np.array([rle_decode(enc, ORIG_SIZE) for enc in rles]).astype(int)\n",
    "    boxes = df_preds_oof['boxes'][idx]\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, pred, boxes, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Pred - {CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, truth, boxes_truth, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Truth - {df_oof[\"cell_type\"][idx]}')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-' * 100)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(img, pred, truth, plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # new folds - fix tta\n",
    "#     LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "#     LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "#     LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11.\n",
    "#     LOG_PATH + \"seb/mrcnn_r50_lossdecay/\",  # 12.\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [3000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.75, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.95, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],  # [1500, 1000, 500],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.75, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0., 0., 0.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    config.split = \"skf\"\n",
    "    configs.append(config)\n",
    "\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "results_s, all_stuff, df_oof_s = inference_single(df, configs, weights, ENSEMBLE_CONFIG, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "results_s, all_stuff, df_oof_s = inference_single(df, configs, weights, ENSEMBLE_CONFIG, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(config.data_config)\n",
    "dataset_s = SartoriusDataset(df_oof_s, transforms=pipelines['val_viz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [np.round(0.05 * i, 2) for i in range(1, 10)]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(1, 18)]\n",
    "\n",
    "scores = tweak_thresholds(\n",
    "    results_s,\n",
    "    dataset_s,\n",
    "    thresholds_mask,\n",
    "    thresholds_nms,\n",
    "    thresholds_conf,\n",
    "    remove_overlap=True\n",
    ")\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    scores_class = scores[c]\n",
    "\n",
    "    if scores_class.shape[2]:\n",
    "        scores_class = scores[c].mean(2) \n",
    "        \n",
    "        idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "        best_score = scores_class[idx]\n",
    "        \n",
    "        threshold_mask = thresholds_mask[idx[0]]\n",
    "        threshold_nms = thresholds_nms[idx[1]]\n",
    "        threshold_conf = thresholds_conf[idx[2]]\n",
    "\n",
    "        print(f\"Best score {best_score:.4f} for thresholds : \")\n",
    "        print(f'- Threshold mask : {threshold_mask}')\n",
    "        print(f'- Threshold nms  : {threshold_nms}')\n",
    "        print(f'- Threshold conf : {threshold_conf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_pred, boxes_pred, cell_types = process_results(\n",
    "    results_s, threshold_mask, threshold_nms, threshold_conf, remove_overlap=True, corrupt=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_single, _ = evaluate(masks_pred, dataset_s, cell_types)\n",
    "\n",
    "print(f' -> IoU mAP : {np.mean(scores_single):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_single, _ = evaluate(masks_pred, dataset_s, cell_types)\n",
    "\n",
    "print(f' -> IoU mAP : {np.mean(scores_single):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_single, _ = evaluate(masks_pred, dataset_s, cell_types)\n",
    "\n",
    "print(f' -> IoU mAP : {np.mean(scores_single):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_s[idx]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "pred = masks_pred[idx].copy().astype(int)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=pred, boxes=boxes_pred[idx])\n",
    "# plot_sample(img, mask=truth)\n",
    "plt.title(f'{CELL_TYPES[cell_types[idx]]} - iou_map={np.mean(scores_single):.3f}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_s[idx]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "pred = masks_pred[idx].copy().astype(int)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=pred, boxes=boxes_pred[idx])\n",
    "# plot_sample(img, mask=truth)\n",
    "plt.title(f'{CELL_TYPES[cell_types[idx]]} - iou_map={np.mean(scores_single):.3f}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_list, merged_bboxes, bboxes, aug_masks, masks = all_stuff\n",
    "\n",
    "bboxes = bboxes.cpu().numpy()\n",
    "merged_bboxes = merged_bboxes.cpu().numpy()\n",
    "proposals = proposal_list[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Number of proposals : {[len(prop) for prop in aug_proposals[0]]}')\n",
    "print(f'Number of merged proposals : {len(proposals)}')\n",
    "print(f'Number of merged boxes : {len(merged_bboxes)}')\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Number of detected boxes (th={0.05 * i:.2f}): {(bboxes[:, 4] > 0.05 * i).sum()}')\n",
    "    \n",
    "print()\n",
    "print(f'Number of pred masks after pp : {len(pred)}')\n",
    "print(f'Number of gt masks : {len(truth)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=None, boxes=merged_bboxes)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_hit = 0.4\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "missed = []\n",
    "for i, preds in enumerate((proposals, bboxes)):\n",
    "    max_ious = []\n",
    "    for b in boxes_truth:\n",
    "        ious = []\n",
    "        for prop in preds[preds[:, 4] > 0.]:\n",
    "            ious.append(bbox_iou(b, prop))\n",
    "\n",
    "        max_ious.append(np.max(ious))\n",
    "\n",
    "    max_ious = np.array(max_ious)\n",
    "    missed.append(boxes_truth[(max_ious < threshold_hit)])\n",
    "\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.histplot(max_ious, bins=20)\n",
    "    plt.axvline(threshold_hit, c=\"salmon\")\n",
    "    t = 'proposals' if i == 0 else \"bboxes\"\n",
    "    plt.title(t + f' - missed {len(missed[-1])}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = (pred.astype(int).max(0) > 0)[..., None]\n",
    "# img_m = img * (1 - m) + 129 * m\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.imshow(img_m)\n",
    "# #         plot_sample(img * (1 - m) + 131 * m, masks.astype(int))\n",
    "# plt.axis(False)\n",
    "# plt.title(img_id)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# cv2.imwrite('test.png', img_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "    pred,\n",
    "    truth,\n",
    "#     boxes=missed[1],\n",
    "#     boxes_2=missed[0],\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_comp = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged, _, picks = mask_nms(\n",
    "#     np.concatenate([pred > 0, masks_comp > 0]),\n",
    "#     np.concatenate([np.ones((len(pred), 5)), 0.1 * np.ones((len(masks_comp), 5))]),\n",
    "#     0.0\n",
    "# )\n",
    "\n",
    "# # merged = pred > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = remove_overlap_naive(merged)\n",
    "# merged = merged.astype(int)\n",
    "# for i in range(len(merged)):\n",
    "#     merged[i] *= (i + 1)\n",
    "\n",
    "# merged = merged.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_map([truth.max(0)], [merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_map([truth.max(0)], [merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_preds_iou(\n",
    "#     img,\n",
    "#     merged.astype(int),\n",
    "#     truth,\n",
    "# #     boxes=missed[1],\n",
    "# #     boxes_2=missed[0],\n",
    "#     plot_tp=True)\n",
    "\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=900,\n",
    "#     height=700,\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(masks_comp.max(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
