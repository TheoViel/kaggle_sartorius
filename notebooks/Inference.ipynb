{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from utils.logger import Config\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.post_process import post_process_preds\n",
    "from inference.validation import inference_val_ens, inference_val\n",
    "\n",
    "from utils.metrics import post_process_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = LOG_PATH + \"2021-11-10/21/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", 'r')))\n",
    "config.model_config = EXP_FOLDER + config.model_config.split('/')[-1]\n",
    "config.data_config = EXP_FOLDER + config.data_config.split('/')[-1]\n",
    "\n",
    "weights = sorted(glob.glob(EXP_FOLDER + \"*.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = prepare_data(fix=config.fix)\n",
    "# results, df_oof = inference_val(df, config, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # single models - LB 0.321\n",
    "    LOG_PATH + \"2021-11-10/10/\",  # 0.3119 / 0.3081  \\\n",
    "    LOG_PATH + \"2021-11-10/11/\",  # 0.3109 / 0.3079  |-> 0.3153 / 0.3112\n",
    "    LOG_PATH + \"2021-11-10/12/\",  # 0.3122 / 0.3091 /\n",
    "]\n",
    "\n",
    "# EXP_FOLDERS = [  # single models\n",
    "#     LOG_PATH + \"2021-11-10/16/\",  # 0.3108 / 0.3075   \\\n",
    "#     LOG_PATH + \"2021-11-10/15/\",  # 0.3107 / 0.3077   |-> 0.3165 / 0.3133\n",
    "#     LOG_PATH + \"2021-11-10/19/\",  # 0.3101 / 0.3074   |\n",
    "#     LOG_PATH + \"2021-11-10/20/\",  # 0.3151 / 0.3116  /\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # single models - livecell (r50)\n",
    "#     LOG_PATH + \"2021-11-12/2/\",  # 0.3151 / 0.3118   - pretrain\n",
    "#     LOG_PATH + \"2021-11-13/0/\",  # 0.3130 / 0.3093   - 700 ext\n",
    "    LOG_PATH + \"2021-11-13/1/\",  # 0.3141 / 0.3112   - schedule\n",
    "#     LOG_PATH + \"2021-11-13/3/\",  # 0.3149 / 0.3119   - schedule + pretrain \n",
    "#     LOG_PATH + \"2021-11-11/7/\",  # 0.3111 / 0.3084\n",
    "#     LOG_PATH + \"2021-11-10/21/\",  # 0.3118 / 0.3102\n",
    "\n",
    "#     LOG_PATH + \"2021-11-13/5/\",  # 0.3130 / 0.3100   - schedule + single\n",
    "#     LOG_PATH + \"2021-11-15/1/\",   # 0.3139 / 0.3097  - schedule + pretrain r101\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-11-10/21/\",  # 0.3078 / 0.3042  \\\n",
    "    LOG_PATH + \"2021-11-11/0/\",   # 0.3068 / 0.3040  |-> 0.3121x / 0.309x\n",
    "    LOG_PATH + \"2021-11-11/1/\",   # 0.3088 / 0.3045 /\n",
    "#     LOG_PATH + \"2021-11-11/3/\",  # 0.3084 / 0.3046\n",
    "#     LOG_PATH + \"2021-11-11/7/\",  # 0.3045 / 0.3012\n",
    "#     LOG_PATH + \"2021-11-12/0/\",  # 0.3077 / 0.3044\n",
    "    LOG_PATH + \"2021-11-15/3/\",  # 0.3077 / 0.3044\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TTA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    configs.append(config)\n",
    "\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = prepare_data(fix=False)\n",
    "results, df_oof = inference_val_ens(df, configs, weights, use_tta=USE_TTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(config.data_config)\n",
    "dataset = SartoriusDataset(df_oof, transforms=pipelines['val_viz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_conf_tweak = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "thresholds_mask_tweak = [0.35, 0.4, 0.45, 0.5, 0.55]\n",
    "\n",
    "best_thresholds_conf = [0.5, 0.5, 0.5]\n",
    "best_thresholds_mask = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = [{} for _ in range(len(CELL_TYPES))]\n",
    "for th_conf in tqdm(thresholds_conf_tweak):\n",
    "    score, scores_classes = evaluate_results(dataset, results, th_conf, 0.5, remove_overlap=False)\n",
    "\n",
    "    for i, (c, s) in enumerate(zip(CELL_TYPES, scores_classes)):\n",
    "        scores[i][th_conf] = s\n",
    "    \n",
    "best_thresholds_conf = [list(score.keys())[np.argmax(list(score.values()))] for score in scores]\n",
    "\n",
    "for i, th in enumerate(best_thresholds_conf):\n",
    "    print(f'Best score for {CELL_TYPES[i]} :\\t{scores[i][th] :.4f}   (th_conf={th})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask_tweak = [0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "scores = [{} for _ in range(len(CELL_TYPES))]\n",
    "for th_mask in tqdm(thresholds_mask_tweak):\n",
    "    score, scores_classes = evaluate_results(dataset, results, best_thresholds_conf, th_mask, remove_overlap=False)\n",
    "\n",
    "    for i, (c, s) in enumerate(zip(CELL_TYPES, scores_classes)):\n",
    "        scores[i][th_mask] = s\n",
    "    \n",
    "best_thresholds_mask = [list(score.keys())[np.argmax(list(score.values()))] for score in scores]\n",
    "\n",
    "for i, th in enumerate(best_thresholds_mask):\n",
    "    print(f'Best score for {CELL_TYPES[i]} :\\t{scores[i][th] :.4f}   (th_mask={th})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'THRESHOLDS_CONF = {best_thresholds_conf}\\nTHRESHOLDS_MASK = {best_thresholds_mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, scores_classes = evaluate_results(\n",
    "    dataset,\n",
    "    results,\n",
    "    best_thresholds_conf,\n",
    "    best_thresholds_mask,\n",
    "    remove_overlap=False\n",
    ")\n",
    "\n",
    "print(f'IoU mAP : {score :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, scores_classes = evaluate_results(\n",
    "    dataset,\n",
    "    results,\n",
    "    best_thresholds_conf,\n",
    "    best_thresholds_mask,\n",
    "    remove_overlap=True\n",
    ")\n",
    "\n",
    "print(f'IoU mAP : {score :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_preds = []\n",
    "for result in results:\n",
    "    masks, _ , _ = post_process_preds(\n",
    "        result,\n",
    "        thresholds_conf=best_thresholds_conf,\n",
    "        thresholds_mask=best_thresholds_mask,\n",
    "        remove_overlap=False\n",
    "    )\n",
    "    masks_preds.append(masks.max(0))\n",
    "    \n",
    "masks_truth = [masks.masks.max(0) for masks in dataset.masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score(np.array(masks_preds), np.array(masks_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    data = dataset[idx]\n",
    "\n",
    "    img = data['img']\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "    boxes_truth = data['gt_bboxes']\n",
    "    \n",
    "    # preds\n",
    "    masks, boxes, c = post_process_preds(\n",
    "        results[idx], best_thresholds_conf, best_thresholds_mask, remove_overlap=True\n",
    "    )\n",
    "    \n",
    "#     sizes = np.max([boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1]], 0)\n",
    "#     masks = masks[sizes < max_size]\n",
    "#     boxes = boxes[sizes < max_size]\n",
    "    \n",
    "    # Score\n",
    "    for i in range(len(truth)):\n",
    "        truth[i] *= (i + 1)\n",
    "    truth = truth.max(0)\n",
    "\n",
    "    pred = masks.copy().astype(int)\n",
    "    for i in range(len(pred)):\n",
    "        pred[i] *= (i + 1)\n",
    "    pred = pred.max(0)\n",
    "\n",
    "    score = iou_map([truth], [pred])\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, pred, boxes, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'{CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, truth, boxes_truth, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'{CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(img, pred, truth, plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "#     LOG_PATH + \"2021-11-12/2/\",  # 0.3151 / 0.3118   - pretrain\n",
    "    LOG_PATH + \"2021-11-13/1/\",  # 0.3141 / 0.3112   - schedule\n",
    "    LOG_PATH + \"2021-11-13/3/\",  # 0.3149 / 0.3119   - schedule + pretrain \n",
    "#     LOG_PATH + \"2021-11-15/1/\",  # 0.3139 / 0.3097  - schedule + pretrain r101\n",
    "#     LOG_PATH + \"2021-11-10/21/\"\n",
    "#     LOG_PATH + \"2021-11-10/20/\",\n",
    "]\n",
    "\n",
    "USE_TTA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    configs.append(config)\n",
    "\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.validation import inference_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False)\n",
    "results, all_stuff, df_oof = inference_single(df, configs, weights, idx=0, use_tta=USE_TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(config.data_config)\n",
    "dataset = SartoriusDataset(df_oof, transforms=pipelines['val_viz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_CONF = [0.35, 0.45, 0.8]\n",
    "THRESHOLDS_MASK = [0.45, 0.45, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, scores_classes = evaluate_results(\n",
    "    dataset,\n",
    "    results,\n",
    "    THRESHOLDS_CONF,\n",
    "    THRESHOLDS_MASK,\n",
    "    remove_overlap=True\n",
    ")\n",
    "\n",
    "print(f'IoU mAP : {score :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(bb1, bb2):\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
    "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "\n",
    "# preds\n",
    "masks, boxes, c = post_process_preds(\n",
    "    results[0], THRESHOLDS_CONF, THRESHOLDS_MASK, remove_overlap=True\n",
    ")\n",
    "\n",
    "#     sizes = np.max([boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1]], 0)\n",
    "#     masks = masks[sizes < max_size]\n",
    "#     boxes = boxes[sizes < max_size]\n",
    "\n",
    "# Score\n",
    "for i in range(len(truth)):\n",
    "    truth[i] *= (i + 1)\n",
    "truth = truth.max(0)\n",
    "\n",
    "pred = masks.copy().astype(int)\n",
    "for i in range(len(pred)):\n",
    "    pred[i] *= (i + 1)\n",
    "pred = pred.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    proposal_list, aug_proposals,\n",
    "    bbox_result, det_bboxes, det_labels, merged_bboxes, aug_bboxes,\n",
    "    segm_result, merged_masks, aug_masks\n",
    ") = all_stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_bboxes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_bboxes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = proposal_list[0].cpu().numpy()\n",
    "# proposals = aug_proposals[0][0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(aug_proposals[0][0].cpu().numpy()), len(aug_proposals[0][1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_bboxes.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_bboxes[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "det_bboxes = det_bboxes.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proposals), len(aug_bboxes[0]), len(aug_bboxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(bbox_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(det_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=None, boxes=proposals)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_hit = 0.4\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "missed = []\n",
    "for i, preds in enumerate((proposals, det_bboxes)):\n",
    "    max_ious = []\n",
    "    for b in boxes_truth:\n",
    "        ious = []\n",
    "        for prop in preds:\n",
    "            ious.append(get_iou(b, prop))\n",
    "\n",
    "        max_ious.append(np.max(ious))\n",
    "\n",
    "    max_ious = np.array(max_ious)\n",
    "    missed.append(boxes_truth[max_ious < threshold_hit])\n",
    "\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.histplot(max_ious, bins=20)\n",
    "    plt.axvline(threshold_hit, c=\"salmon\")\n",
    "    plt.title('proposals' if i == 0 else \"det_bboxes\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(img, plotly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "    pred,\n",
    "    truth,\n",
    "    boxes=missed[1],\n",
    "    boxes_2=missed[0],\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
