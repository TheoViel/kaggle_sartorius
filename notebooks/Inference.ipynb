{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from utils.logger import Config, save_to_folder\n",
    "from utils.rle import rle_encode, rle_decode\n",
    "\n",
    "from inference.tweaking import *\n",
    "from inference.validation import *\n",
    "from inference.post_process import *\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.validation import inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # new folds\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_new_splits/\", # 7. maskrcnn rx101 - 0.3120\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\",  # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-21/0/\",  #  17. htc rx101 - 0.3119\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. cascade b4 c\n",
    "    LOG_PATH + \"seb/mrcnn_b5/\", # 19. mrcnn b4 - 0.3086\n",
    "    LOG_PATH + \"2021-12-22/2/\",  #  20. cascade b6 192 crops - 0.3118\n",
    "    LOG_PATH + \"2021-12-22/6/\",  #  21. htc b4 - 0.3083\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "    LOG_PATH + \"seb/cascade_resnext101_32x8/\",  # 23. cascade rx101_32x8 - 0.3121\n",
    "    LOG_PATH + \"seb/mrcnn_rx101_decay_bn_flip_aug/\",  # 24. mrcnn rx101 - 0.3141\n",
    "    LOG_PATH + \"seb/mrcnn_r50_bn_flip_decay/\",  # 25. mrcnn r50 0.3141\n",
    "    LOG_PATH + \"seb/mrcnn_rx101_64x4_flip_bn_decay_64x4\",  # 26. mrcnn rx101_64x4 - 0.3121\n",
    "    LOG_PATH + \"2021-12-28/2/\",  # 28. mrcnn rx50 gnws - \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # id #3 - Cort 0.4083 / 0.4091 pp\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3121\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # Shsy5y - 0.2399 / 0.2403 no tta mask\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-22/2/\",  #  20. cascade b6 192 crops - 0.3118\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4/\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # Astro - 0.2145 / 0.2151 no tta mask / 0.2165 pp no tta mask\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4/\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [ # Cort - 0.4095\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"seb/mrcnn_b5/\", # 19. mrcnn b5 - 0.3086\n",
    "    LOG_PATH + \"2021-12-22/6/\",  #  21. htc b4 - 0.3083\n",
    "    LOG_PATH + \"seb/mrcnn_rx101_decay_bn_flip_aug/\",  # 24. mrcnn rx101 - 0.3141\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(EXP_FOLDERS) <= 6:  # small ensemble \n",
    "    EXP_FOLDERS_CORT = EXP_FOLDERS\n",
    "    EXP_FOLDERS_ASTRO = EXP_FOLDERS\n",
    "    EXP_FOLDERS_SHSY5Y = EXP_FOLDERS\n",
    "    EXP_FOLDER_CLS = EXP_FOLDERS\n",
    "\n",
    "assert [f for f in EXP_FOLDERS if f in EXP_FOLDERS_CORT] == EXP_FOLDERS_CORT\n",
    "assert [f for f in EXP_FOLDERS if f in EXP_FOLDERS_ASTRO] == EXP_FOLDERS_ASTRO\n",
    "assert [f for f in EXP_FOLDERS if f in EXP_FOLDERS_SHSY5Y] == EXP_FOLDERS_SHSY5Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG_SINGLE = {  # single\n",
    "    \"use_tta\": True,\n",
    "    \"use_tta_masks\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [3000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.75, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.95, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],  # [1500, 1000, 500],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.75, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.3, 0.5],\n",
    "    \n",
    "    \"use_for_cort\": [f in EXP_FOLDERS_CORT for f in EXP_FOLDERS],\n",
    "    \"use_for_astro\": [f in EXP_FOLDERS_ASTRO for f in EXP_FOLDERS],\n",
    "    \"use_for_shsy5y\": [f in EXP_FOLDERS_SHSY5Y for f in EXP_FOLDERS],\n",
    "    \"use_for_cls\": [f in EXP_FOLDER_CLS for f in EXP_FOLDERS]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG_ENS = {  # ens\n",
    "    \"use_tta\": True,\n",
    "    \"use_tta_masks\": True,  # False\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [5000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.7, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.9, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.7, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.25, 0.5],\n",
    "    \n",
    "    \"use_for_cort\": [f in EXP_FOLDERS_CORT for f in EXP_FOLDERS],\n",
    "    \"use_for_astro\": [f in EXP_FOLDERS_ASTRO for f in EXP_FOLDERS],\n",
    "    \"use_for_shsy5y\": [f in EXP_FOLDERS_SHSY5Y for f in EXP_FOLDERS],\n",
    "    \"use_for_cls\": [f in EXP_FOLDER_CLS for f in EXP_FOLDERS]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = ENSEMBLE_CONFIG_SINGLE if len(EXP_FOLDERS) == 1 else ENSEMBLE_CONFIG_ENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE = None  # \"cort\"  #  # \"shsy5y\"  # \"astro\"\n",
    "# If you wish to run the inference only on one cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "\n",
    "    try:\n",
    "        _ = config.split\n",
    "        remove_anomalies = config.remove_anomalies\n",
    "    except:\n",
    "        config.split = \"skf\"\n",
    "        remove_anomalies = False\n",
    "\n",
    "    configs.append(config)\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=remove_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(configs[0].data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_results, dfs_val = inference_val(df, configs, weights, ENSEMBLE_CONFIG, cell_type=CELL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.concat(dfs_val).reset_index(drop=True)\n",
    "\n",
    "pipelines = define_pipelines(config.data_config)\n",
    "\n",
    "datasets = [SartoriusDataset(df_val, transforms=pipelines['val_viz'], precompute_masks=False) for df_val in dfs_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask = [0.45, 0.45, 0.45]\n",
    "best_thresholds_nms = [0.1, 0.1, 0.05]\n",
    "best_thresholds_conf = [0.3, 0.4, 0.7]\n",
    "best_min_sizes = [0, 0, 0]  # [50, 125, 75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.05, 0.1, 0.15]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(4, 17)]\n",
    "min_sizes = [0, 50, 75, 100, 150]  # [0, 25, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold, (df_, results) in enumerate(zip(dfs_val, all_results)):\n",
    "    for i, (b, _) in enumerate(results):\n",
    "        pred = np.argmax(np.bincount(b[:, 5].astype(int)))\n",
    "        gt = CELL_TYPES.index(df_['cell_type'][i])\n",
    "\n",
    "        if pred != gt:\n",
    "            print(f'Fold {fold}, img {df_[\"id\"][i]} (idx {i}), pred {pred}, gt {gt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_cell_types = []\n",
    "\n",
    "for dataset, results in zip(datasets, all_results):\n",
    "    scores, cell_types = tweak_thresholds(\n",
    "        results,\n",
    "        dataset,\n",
    "        thresholds_mask,\n",
    "        thresholds_nms,\n",
    "        thresholds_conf,\n",
    "        min_sizes=min_sizes,\n",
    "        remove_overlap=True,\n",
    "        corrupt=True,\n",
    "    )\n",
    "    all_scores.append(scores)\n",
    "    all_cell_types += cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CELL_TYPE is not None:\n",
    "    for i in range(len(weights[0])):\n",
    "        if not all_scores[i][0].shape[-1] and not all_scores[i][1].shape[-1]:\n",
    "            all_scores[i][0] = all_scores[i][2].copy()\n",
    "            all_scores[i][1] = all_scores[i][2].copy()\n",
    "\n",
    "        if not all_scores[i][2].shape[-1] and not all_scores[i][1].shape[-1]:\n",
    "            all_scores[i][2] = all_scores[i][0].copy()\n",
    "            all_scores[i][1] = all_scores[i][0].copy()\n",
    "\n",
    "        if not all_scores[i][0].shape[-1] and not all_scores[i][2].shape[-1]:\n",
    "            all_scores[i][0] = all_scores[i][1].copy()\n",
    "            all_scores[i][2] = all_scores[i][1].copy()\n",
    "\n",
    "scores_tweak = [\n",
    "    np.concatenate([scores_fold[c] for scores_fold in all_scores if scores_fold[c].shape[-1]], -2)\n",
    "    for c in range(len(CELL_TYPES))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, best_min_sizes = [], [], [], []\n",
    "best_scores = []\n",
    "\n",
    "for c in range(len(CELL_TYPES)):  # 64\n",
    "    print(f' -> Cell type {CELL_TYPES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(-2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (\n",
    "        thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[3]], min_sizes[idx[2]]\n",
    "    )\n",
    "    best_thresholds_mask.append(best_thresholds_c[0])\n",
    "    best_thresholds_nms.append(best_thresholds_c[1])\n",
    "    best_thresholds_conf.append(best_thresholds_c[2])\n",
    "    best_min_sizes.append(best_thresholds_c[3])\n",
    "\n",
    "    print(\n",
    "        f\"Best score {best_score:.4f} for thresholds (mask, nms, conf, min_size): {best_thresholds_c}\\n\"\n",
    "    )\n",
    "\n",
    "# ws = [Counter(df_oof['cell_type'])[c] for c in CELL_TYPES]\n",
    "ws = [Counter(all_cell_types)[c] for c in range(len(CELL_TYPES))]\n",
    "\n",
    "best_score = np.average(best_scores, weights=ws)\n",
    "\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for c in range(len(CLASSES)):\n",
    "#     print(f\"\\nClass {CLASSES[c]}\")\n",
    "#     for idx_mask, threshold_mask in enumerate(thresholds_mask):\n",
    "#         for idx_nms, threshold_nms in enumerate(thresholds_nms):\n",
    "#             print(f\"\\n-> Threshold mask = {threshold_mask} - Threshold nms = {threshold_nms}\")\n",
    "#             for s, conf in zip(np.mean(scores_tweak[c][idx_mask, idx_nms], 0) , thresholds_conf):\n",
    "#                 print(f\"Threshold conf = {conf} - score = {s:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'THRESHOLDS_MASK = {best_thresholds_mask}')\n",
    "print(f'THRESHOLDS_NMS = {best_thresholds_nms}')\n",
    "print(f'THRESHOLDS_CONF = {best_thresholds_conf}')\n",
    "print(f'MIN_SIZES = {best_min_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [[], [], []]\n",
    "metadata = []\n",
    "\n",
    "for results, dataset in zip(all_results, datasets):\n",
    "    masks_pred, boxes_pred, cell_types = process_results(\n",
    "        results,\n",
    "        best_thresholds_mask,\n",
    "        best_thresholds_nms,\n",
    "        best_thresholds_conf,\n",
    "        70,\n",
    "        remove_overlap=True,\n",
    "        corrupt=True\n",
    "    )\n",
    "    \n",
    "    scores, scores_per_class = evaluate(\n",
    "        masks_pred,\n",
    "        dataset,\n",
    "        cell_types\n",
    "    )\n",
    "\n",
    "    for masks, boxes, cell_type_pred, img_id, score, cell_type in zip(\n",
    "        masks_pred, boxes_pred, cell_types, dataset.df['id'].values, scores, dataset.df['cell_type'].values\n",
    "    ):\n",
    "        metadata.append({\n",
    "            'id': img_id,\n",
    "            'cell_type': cell_type,\n",
    "            'cell_type_pred': cell_type_pred,\n",
    "            'rles': [rle_encode(mask) for mask in masks],\n",
    "            'boxes': boxes.tolist(),\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "    for i, s in enumerate(scores_per_class):\n",
    "        all_scores[i] += s\n",
    "        \n",
    "#     del masks_pred, boxes_pred, cell_types\n",
    "#     gc.collect()\n",
    "\n",
    "#     break\n",
    "    \n",
    "df_preds_oof = pd.DataFrame.from_dict(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save no thesholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ens_12/\"\n",
    "\n",
    "SAVE_DIR = OUT_PATH + name\n",
    "\n",
    "# assert not os.path.exists(SAVE_DIR)\n",
    "# os.mkdir(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx, (results, dataset) in enumerate(zip(all_results, datasets)):\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        id_ = dataset.df['id'][i]\n",
    "        masks = results[i][1]\n",
    "        boxes = results[i][0]\n",
    "\n",
    "        np.save(SAVE_DIR + f\"masks_{id_}.npy\", masks)\n",
    "        np.save(SAVE_DIR + f\"boxes_{id_}.npy\", boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SartoriusDataset(df_oof, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(len(dataset)):\n",
    "    if df_oof['plate'][idx] != \"cort[density]\":\n",
    "        continue\n",
    "    \n",
    "    score = df_preds_oof['score'][idx]\n",
    "    c = df_preds_oof['cell_type'][idx]\n",
    "    \n",
    "    data = dataset[idx]\n",
    "    img = data['img']\n",
    "    \n",
    "    # truth\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "    boxes_truth = data['gt_bboxes']\n",
    "    \n",
    "    # preds\n",
    "    rles = df_preds_oof['rles'][idx]\n",
    "    pred = np.array([rle_decode(enc, ORIG_SIZE) for enc in rles]).astype(int)\n",
    "    boxes = df_preds_oof['boxes'][idx]\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, pred, boxes, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Pred - {CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, truth, boxes_truth, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Truth - {df_oof[\"cell_type\"][idx]}')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-' * 100)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(img, pred, truth, plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
