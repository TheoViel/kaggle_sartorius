{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from inference.post_process import *\n",
    "from utils.logger import Config\n",
    "from inference.validation import *\n",
    "from inference.tweaking import *\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.validation import inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # single models - LB 0.321\n",
    "    LOG_PATH + \"2021-11-10/10/\",  # 0.3119 / 0.3081  \\\n",
    "    LOG_PATH + \"2021-11-10/11/\",  # 0.3109 / 0.3079  |-> 0.3153 / 0.3112\n",
    "    LOG_PATH + \"2021-11-10/12/\",  # 0.3122 / 0.3091 /\n",
    "]\n",
    "\n",
    "# EXP_FOLDERS = [  # single models\n",
    "#     LOG_PATH + \"2021-11-10/16/\",  # 0.3108 / 0.3075   \\\n",
    "#     LOG_PATH + \"2021-11-10/15/\",  # 0.3107 / 0.3077   |-> 0.3165 / 0.3133\n",
    "#     LOG_PATH + \"2021-11-10/19/\",  # 0.3101 / 0.3074   |\n",
    "#     LOG_PATH + \"2021-11-10/20/\",  # 0.3151 / 0.3116  /\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # single models - livecell (r50)\n",
    "#     LOG_PATH + \"2021-11-12/2/\",  # 0.3151 / 0.3118   - pretrain\n",
    "#     LOG_PATH + \"2021-11-13/0/\",  # 0.3130 / 0.3093   - 700 ext\n",
    "    LOG_PATH + \"2021-11-13/1/\",  # 0.3141 / 0.3112   - schedule\n",
    "    LOG_PATH + \"2021-11-13/3/\",  # 0.3149 / 0.3119   - schedule + pretrain \n",
    "#     LOG_PATH + \"2021-11-11/7/\",  # 0.3111 / 0.3084\n",
    "#     LOG_PATH + \"2021-11-10/21/\",  # 0.3118 / 0.3102\n",
    "\n",
    "#     LOG_PATH + \"2021-11-13/5/\",  # 0.3130 / 0.3100   - schedule + single\n",
    "#     LOG_PATH + \"2021-11-15/1/\",   # 0.3139 / 0.3097  - schedule + pretrain r101\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-11-13/1/\",  # 0.3142 / 0.3129   - schedule\n",
    "#     LOG_PATH + \"2021-11-13/3/\",  # 0.3150 / 0.3135   - schedule + pretrain \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_FOLDERS = [  # 1st batch\n",
    "#     LOG_PATH + \"2021-11-10/21/\",  # 0.3078 / 0.3042  \\\n",
    "#     LOG_PATH + \"2021-11-11/0/\",   # 0.3068 / 0.3040  |-> 0.3121x / 0.309x\n",
    "#     LOG_PATH + \"2021-11-11/1/\",   # 0.3088 / 0.3045 /\n",
    "# #     LOG_PATH + \"2021-11-11/3/\",  # 0.3084 / 0.3046\n",
    "# #     LOG_PATH + \"2021-11-11/7/\",  # 0.3045 / 0.3012\n",
    "# #     LOG_PATH + \"2021-11-12/0/\",  # 0.3077 / 0.3044\n",
    "#     LOG_PATH + \"2021-11-15/3/\",  # 0.3077 / 0.3044\n",
    "# ]\n",
    "\n",
    "EXP_FOLDERS = [  # 2nd batch \n",
    "#     LOG_PATH + \"2021-11-15/3/\",  # rx101 pretrain + extra - 0.3153\n",
    "    LOG_PATH + \"2021-11-16/0/\",  # r50 pretrain + extra - 0.3105\n",
    "#     LOG_PATH + \"2021-11-16/3/\",  # rx101 pretrain  - 0.3155\n",
    "#     LOG_PATH + \"2021-11-17/0/\",  # r50 pretrain - 0.3102\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    configs.append(config)\n",
    "\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = prepare_data(fix=False)\n",
    "all_results, dfs_val = inference_val(df, configs, weights, use_tta=USE_TTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.concat(dfs_val).reset_index(drop=True)\n",
    "pipelines = define_pipelines(config.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [SartoriusDataset(df_val, transforms=pipelines['val_viz'], precompute_masks=False) for df_val in dfs_val]\n",
    "# dataset = SartoriusDataset(df_oof, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask = [0.45, 0.45, 0.45]\n",
    "best_thresholds_nms = [0.45, 0.1, 0.05]\n",
    "best_thresholds_conf = [0.35, 0.45, 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "\n",
    "thresholds_nms = [np.round(0.05 * i, 2) for i in range(1, 10)]\n",
    "\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(1, 18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for dataset, results in zip(datasets, all_results):\n",
    "    scores = tweak_thresholds(\n",
    "        results,\n",
    "        dataset,\n",
    "        thresholds_mask,\n",
    "        thresholds_nms,\n",
    "        thresholds_conf,\n",
    "        remove_overlap=True\n",
    "    )\n",
    "    all_scores.append(scores)\n",
    "#     break\n",
    "\n",
    "scores_tweak = [\n",
    "    np.concatenate([scores_fold[c] for scores_fold in all_scores], 2)\n",
    "    for c in range(len(CELL_TYPES))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = []\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    print(f' -> Cell type {CELL_TYPES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[2]])\n",
    "    best_thresholds_mask[c] = best_thresholds_c[0]\n",
    "    best_thresholds_nms[c] = best_thresholds_c[1]\n",
    "    best_thresholds_conf[c] = best_thresholds_c[2]\n",
    "\n",
    "    print(f\"Best score {best_score:.4f} for thresholds (mask, nms, conf): {best_thresholds_c}\\n\")\n",
    "\n",
    "best_score = np.average(best_scores, weights=list(Counter(df_oof['cell_type']).values()))\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for c in range(len(CELL_TYPES)):\n",
    "#     print(f\"\\nClass {CELL_TYPES[c]}\")\n",
    "#     for idx_mask, threshold_mask in enumerate(thresholds_mask):\n",
    "#         for idx_nms, threshold_nms in enumerate(thresholds_nms):\n",
    "#             print(f\"\\n-> Threshold mask = {threshold_mask} - Threshold nms = {threshold_nms}\")\n",
    "#             try:\n",
    "#                 for s, conf in zip(np.mean(scores_tweak[c][idx_mask, idx_nms], 0) , thresholds_conf):\n",
    "#                     print(f\"Threshold conf = {conf} - score = {s:.4f}\")\n",
    "#             except:\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'THRESHOLDS_MASK = {best_thresholds_mask}')\n",
    "print(f'THRESHOLDS_NMS = {best_thresholds_nms}')\n",
    "print(f'THRESHOLDS_CONF = {best_thresholds_conf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [[], [], []]\n",
    "\n",
    "for results, dataset in zip(all_results, datasets):\n",
    "    masks_pred, boxes_pred, cell_types = process_results(\n",
    "        results, best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, remove_overlap=True\n",
    "    )\n",
    "    \n",
    "    scores = evaluate(\n",
    "        masks_pred,\n",
    "        dataset,\n",
    "        cell_types\n",
    "    )\n",
    "    \n",
    "    for i, s in enumerate(scores):\n",
    "        all_scores[i] += s\n",
    "        \n",
    "    del masks_pred, boxes_pred, cell_types\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.mean(np.concatenate(all_scores))\n",
    "scores_class = [np.mean(s) for s in all_scores if len(s)]\n",
    "\n",
    "print(f' -> IoU mAP : {score:.4f}\\n')\n",
    "\n",
    "for s, c in zip(scores_class, CELL_TYPES):\n",
    "    print(f'{c} : {s:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_preds = []\n",
    "for result in results:\n",
    "    masks, _ , _ = post_process_preds(\n",
    "        result,\n",
    "        thresholds_conf=best_thresholds_conf,\n",
    "        thresholds_mask=best_thresholds_mask,\n",
    "        remove_overlap=False\n",
    "    )\n",
    "    masks_preds.append(masks.max(0))\n",
    "    \n",
    "masks_truth = [masks.masks.max(0) for masks in dataset.masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score(np.array(masks_preds), np.array(masks_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "for idx in range(10):\n",
    "    data = dataset[idx]\n",
    "\n",
    "    img = data['img']\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "    boxes_truth = data['gt_bboxes']\n",
    "    \n",
    "    # preds\n",
    "    masks, boxes, c = post_process_preds(\n",
    "        results[idx], best_thresholds_conf, best_thresholds_mask, remove_overlap=False\n",
    "    )\n",
    "    \n",
    "#     sizes = np.max([boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1]], 0)\n",
    "#     masks = masks[sizes < max_size]\n",
    "#     boxes = boxes[sizes < max_size]\n",
    "    \n",
    "    # Score\n",
    "    for i in range(len(truth)):\n",
    "        truth[i] *= (i + 1)\n",
    "    truth = truth.max(0)\n",
    "\n",
    "    pred = masks.copy().astype(int)\n",
    "    for i in range(len(pred)):\n",
    "        pred[i] *= (i + 1)\n",
    "    pred = pred.max(0)\n",
    "\n",
    "    score = iou_map([truth], [pred])\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, pred, boxes, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'{CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, truth, boxes_truth, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'{CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(img, pred, truth, plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # 2nd batch \n",
    "    LOG_PATH + \"2021-11-15/3/\",  # rx101 pretrain + extra - 0.3117\n",
    "    LOG_PATH + \"2021-11-16/0/\",  # r50 pretrain + extra - 0.3105\n",
    "    LOG_PATH + \"2021-11-16/3/\",  # rx101 pretrain  - 0.3129\n",
    "    LOG_PATH + \"2021-11-17/0/\",  # r50 pretrain - 0.3102\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    configs.append(config)\n",
    "\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False)\n",
    "results_s, all_stuff, df_oof_s = inference_single(df, configs, weights, idx=0, use_tta=USE_TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(config.data_config)\n",
    "dataset_s = SartoriusDataset(df_oof_s, transforms=pipelines['val_viz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "\n",
    "thresholds_nms = [np.round(0.05 * i, 2) for i in range(1, 10)]\n",
    "\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(1, 18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = tweak_thresholds(\n",
    "    results_s,\n",
    "    dataset_s,\n",
    "    thresholds_mask,\n",
    "    thresholds_nms,\n",
    "    thresholds_conf,\n",
    "    remove_overlap=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(CELL_TYPES)):\n",
    "    scores_class = scores[c]\n",
    "\n",
    "    if scores_class.shape[2]:\n",
    "        scores_class = scores[c].mean(2) \n",
    "        \n",
    "        idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "        best_score = scores_class[idx]\n",
    "\n",
    "        print(f\"Best score {best_score:.4f} for thresholds : \")\n",
    "        print(f'Threshold mask : {thresholds_mask[idx[0]]}')\n",
    "        print(f'Threshold nms  : {thresholds_nms[idx[1]]}')\n",
    "        print(f'Threshold conf : {thresholds_conf[idx[2]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in range(len(CELL_TYPES)):\n",
    "#     print(f\"\\nClass {CELL_TYPES[c]}\")\n",
    "#     for idx_mask, threshold_mask in enumerate(thresholds_mask):\n",
    "#         for idx_nms, threshold_nms in enumerate(thresholds_nms):\n",
    "#             print(f\"\\n-> Threshold mask = {threshold_mask} - Threshold nms = {threshold_nms}\")\n",
    "#             try:\n",
    "#                 for s, conf in zip(np.mean(scores[c][idx_mask][idx_nms], 0) , thresholds_conf):\n",
    "#                     print(f\"Threshold conf = {conf} - score = {s:.4f}\")\n",
    "#             except:\n",
    "#                 break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = thresholds_mask[idx[0]]\n",
    "thresholds_nms = thresholds_nms[idx[1]]\n",
    "thresholds_conf = thresholds_conf[idx[2]]\n",
    "\n",
    "masks_pred, boxes_pred, cell_types = process_results(\n",
    "    results_s, thresholds_mask, thresholds_nms, thresholds_conf, remove_overlap=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_single = evaluate(masks_pred, dataset_s, cell_types)\n",
    "\n",
    "print(f' -> IoU mAP : {np.mean(np.concatenate(scores_single)):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_s[idx]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "\n",
    "for i in range(len(truth)):\n",
    "    truth[i] *= (i + 1)\n",
    "truth = truth.max(0)\n",
    "\n",
    "pred = masks_pred[idx].copy()\n",
    "pred = remove_overlap_naive(pred)\n",
    "pred = pred.astype(int)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred[i] *= (i + 1)\n",
    "pred = pred.max(0)\n",
    "\n",
    "s = iou_map([truth], [pred])\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=pred, boxes=boxes_pred[idx])\n",
    "# plot_sample(img, mask=truth)\n",
    "plt.title(f'{CELL_TYPES[cell_types[idx]]} - iou_map={s:.3f}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_s[idx]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "\n",
    "for i in range(len(truth)):\n",
    "    truth[i] *= (i + 1)\n",
    "truth = truth.max(0)\n",
    "\n",
    "pred = masks_pred[idx].copy()\n",
    "pred = remove_overlap_naive(pred)\n",
    "pred = pred.astype(int)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred[i] *= (i + 1)\n",
    "pred = pred.max(0)\n",
    "\n",
    "s = iou_map([truth], [pred])\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=pred, boxes=boxes_pred[idx])\n",
    "# plot_sample(img, mask=truth)\n",
    "plt.title(f'{CELL_TYPES[cell_types[idx]]} - iou_map={s:.3f}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    proposal_list, aug_proposals,\n",
    "    bboxes, merged_bboxes, aug_bboxes,\n",
    "    masks, merged_masks, aug_masks,\n",
    ") = all_stuff\n",
    "\n",
    "bboxes = bboxes.cpu().numpy()\n",
    "proposals = proposal_list[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of proposals : {[len(prop) for prop in aug_proposals[0]]}')\n",
    "print(f'Number of merged proposals : {len(proposals)}')\n",
    "print(f'Number of merged boxes : {len(merged_bboxes)}')\n",
    "print(f'Number of detected boxes (th=0.): {(bboxes[:, 4] > 0.).sum()}')\n",
    "print(f'Number of detected boxes (th=0.1): {(bboxes[:, 4] > 0.1).sum()}')\n",
    "print(f'Number of detected boxes (th=0.2): {(bboxes[:, 4] > 0.2).sum()}')\n",
    "print(f'Number of detected boxes (th=0.3): {(bboxes[:, 4] > 0.3).sum()}')\n",
    "print(f'Number of detected masks: {len(masks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=None, boxes=proposals)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_hit = 0.4\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "missed = []\n",
    "for i, preds in enumerate((proposals, bboxes)):\n",
    "    max_ious = []\n",
    "    for b in boxes_truth:\n",
    "        ious = []\n",
    "        for prop in preds[preds[:, 4] > 0.]:\n",
    "            ious.append(bbox_iou(b, prop))\n",
    "\n",
    "        max_ious.append(np.max(ious))\n",
    "\n",
    "    max_ious = np.array(max_ious)\n",
    "    missed.append(boxes_truth[max_ious < threshold_hit])\n",
    "\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.histplot(max_ious, bins=20)\n",
    "    plt.axvline(threshold_hit, c=\"salmon\")\n",
    "    t = 'proposals' if i == 0 else \"bboxes\"\n",
    "    plt.title(t + f' - missed {len(missed[-1])}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "    pred,\n",
    "    truth,\n",
    "#     boxes=missed[1],\n",
    "#     boxes_2=missed[0],\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "    pred,\n",
    "    truth,\n",
    "#     boxes=missed[1],\n",
    "#     boxes_2=missed[0],\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
