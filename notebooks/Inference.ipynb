{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to perform inference on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from utils.logger import Config, save_to_folder\n",
    "from utils.rle import rle_encode, rle_decode\n",
    "\n",
    "from inference.tweaking import *\n",
    "from inference.validation import *\n",
    "from inference.post_process import *\n",
    "\n",
    "from data.preparation import prepare_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "from inference.validation import inference_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Old ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # PL\n",
    "    LOG_PATH + \"2021-12-16/1/\",  #  Cascade rx101 - 0.3152\n",
    "    LOG_PATH + \"2021-12-17/2/\",  #  Cascade b6 - 0.3157\n",
    "    LOG_PATH + \"seb/pl_mrcnn_resnet50_decay/\",  # 12. mrcnn r50 - 0.3158\n",
    "    LOG_PATH + \"seb/pl_mrcnn_resnext101_decay/\",  # 12. mrcnn rx101 - 0.3169\n",
    "]\n",
    "\n",
    "EXP_FOLDERS = [  # PL filtered\n",
    "    LOG_PATH + \"2021-12-18/3/\",  #  Cascade rx101 - 0.\n",
    "    LOG_PATH + \"2021-12-19/0/\",   # Cascade r50\n",
    "    LOG_PATH + \"2021-12-19/1/\",  #  Cascade b5 - 0.\n",
    "    LOG_PATH + \"2021-12-19/6/\",  # 12. mrcnn rx101 - 0.\n",
    "    LOG_PATH + \"2021-12-20/0/\",  # 12. mrcnn r50 - 0.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ENS_7\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3127\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_new_splits/\", # 7. maskrcnn rx101 - 0.3120\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ENS_8\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3121\n",
    "#     LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "#     LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "#     LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # new folds\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_new_splits/\", # 7. maskrcnn rx101 - 0.3120\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\",  # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-21/0/\",  #  17. htc rx101 - 0.3119\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. cascade b4 c\n",
    "    LOG_PATH + \"seb/mrcnn_b5/\", # 19. mrcnn b4 - 0.3086\n",
    "    LOG_PATH + \"2021-12-22/2/\",  #  20. cascade b6 192 crops - 0.3118\n",
    "    LOG_PATH + \"2021-12-22/6/\",  #  21. htc b4 - 0.3083\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ens 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_ASTRO = [  # Astro - 0.2141\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-21/0/\",  #  17. htc rx101 - 0.3119\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_SHSY5Y = [  # Shsy5y - 0.2396\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn rx101 0.3131\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-22/2/\",  #  20. cascade b6 192 crops - 0.3118\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_CORT = [  # ENS 9 - Cort 0.4085\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3121\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-21/0/\",  #  17. htc rx101 - 0.3119\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. cascade b4 - 0.3110\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER_CLS = [LOG_PATH + \"seb/mrcnn_r50_lossdecay/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3121\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_new_splits/\", # 8. maskrcnn r50 - 0.3118\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"2021-12-20/1/\",  #  16. Cascade rx101_64x4 - 0.3130\n",
    "    LOG_PATH + \"2021-12-21/0/\",  #  17. htc rx101 - 0.3119\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. cascade b4 - 0.3110\n",
    "    LOG_PATH + \"2021-12-22/2/\",  #  20. cascade b6 192 crops - 0.3118\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ens 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_ASTRO = [  # Astro - 0.2141\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4/\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_SHSY5Y = [  # Shsy5y - 0.2396\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11. mrcnn rx101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. Cascade b4 - 0.3110\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4/\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_CORT = [\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3121\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. Cascade b4 - 0.3110\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3121\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3141\n",
    "    LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3125\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\", # 11. mrcnn r101 0.3131\n",
    "    LOG_PATH + \"seb/mrcnn_r50_lossdecay/\", # 12. mrcnn r50 0.3125\n",
    "    LOG_PATH + \"2021-12-15/0/\",  # 14. Cascade b6 - 0.3121\n",
    "    LOG_PATH + \"2021-12-15/1/\",  # 15. htc r50 - 0.3121\n",
    "    LOG_PATH + \"seb/cascade_b4/\", # 18. Cascade b4 - 0.3110\n",
    "    LOG_PATH + \"seb/mrcnn_r101_64x4/\",  # 22. mrcnn rx101_64x4 - 0.3127\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(EXP_FOLDERS) == 1:  # single model\n",
    "    EXP_FOLDERS_CORT = EXP_FOLDERS\n",
    "    EXP_FOLDERS_ASTRO = EXP_FOLDERS\n",
    "    EXP_FOLDERS_SHSY5Y = EXP_FOLDERS\n",
    "    EXP_FOLDER_CLS = EXP_FOLDERS\n",
    "\n",
    "assert [f for f in EXP_FOLDERS if f in EXP_FOLDERS_CORT] == EXP_FOLDERS_CORT\n",
    "assert [f for f in EXP_FOLDERS if f in EXP_FOLDERS_ASTRO] == EXP_FOLDERS_ASTRO\n",
    "assert [f for f in EXP_FOLDERS if f in EXP_FOLDERS_SHSY5Y] == EXP_FOLDERS_SHSY5Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_to_folder(EXP_FOLDERS, name=\"dataset_ens_10/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "    \"compute_cell_type\" : len(EXP_FOLDERS) > 3,\n",
    "    \"skip_effnet\": len(EXP_FOLDERS) > 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [5000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.7, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.9, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.7, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.25, 0.5],\n",
    "    \n",
    "    \"use_for_cort\": [f in EXP_FOLDERS_CORT for f in EXP_FOLDERS],\n",
    "    \"use_for_astro\": [f in EXP_FOLDERS_ASTRO for f in EXP_FOLDERS],\n",
    "    \"use_for_shsy5y\": [f in EXP_FOLDERS_SHSY5Y for f in EXP_FOLDERS],\n",
    "    \"use_for_cls\": [f in EXP_FOLDER_CLS for f in EXP_FOLDERS]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"exp_folders\": EXP_FOLDERS,\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [3000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.75, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.95, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.75, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.3, 0.5],\n",
    "    \n",
    "    \"use_for_cort\": [f in EXP_FOLDERS_CORT for f in EXP_FOLDERS],\n",
    "    \"use_for_astro\": [f in EXP_FOLDERS_ASTRO for f in EXP_FOLDERS],\n",
    "    \"use_for_shsy5y\": [f in EXP_FOLDERS_SHSY5Y for f in EXP_FOLDERS],\n",
    "    \"use_for_cls\": [f in EXP_FOLDER_CLS for f in EXP_FOLDERS]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "\n",
    "    try:\n",
    "        _ = config.split\n",
    "        remove_anomalies = config.remove_anomalies\n",
    "    except:\n",
    "        config.split = \"skf\"\n",
    "        remove_anomalies = False\n",
    "\n",
    "    configs.append(config)\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=remove_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_results, dfs_val = inference_val(df, configs, weights, ENSEMBLE_CONFIG, cell_type=CELL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.concat(dfs_val).reset_index(drop=True)\n",
    "\n",
    "pipelines = define_pipelines(config.data_config)\n",
    "\n",
    "datasets = [SartoriusDataset(df_val, transforms=pipelines['val_viz'], precompute_masks=False) for df_val in dfs_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask = [0.45, 0.45, 0.45]\n",
    "best_thresholds_nms = [0.1, 0.1, 0.05]\n",
    "best_thresholds_conf = [0.3, 0.4, 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [0.05, 0.1, 0.15]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(4, 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fold, (df_, results) in enumerate(zip(dfs_val, all_results)):\n",
    "    for i, (b, _) in enumerate(results):\n",
    "        pred = np.argmax(np.bincount(b[:, 5].astype(int)))\n",
    "        gt = CELL_TYPES.index(df_['cell_type'][i])\n",
    "\n",
    "        if pred != gt:\n",
    "            print(f'Fold {fold}, idx {i}, pred {pred}, gt {gt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "all_cell_types = []\n",
    "\n",
    "for dataset, results in zip(datasets, all_results):\n",
    "    scores, cell_types = tweak_thresholds(\n",
    "        results,\n",
    "        dataset,\n",
    "        thresholds_mask,\n",
    "        thresholds_nms,\n",
    "        thresholds_conf,\n",
    "        remove_overlap=True,\n",
    "        corrupt=True,\n",
    "    )\n",
    "    all_scores.append(scores)\n",
    "    all_cell_types += cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CELL_TYPE is not None:\n",
    "    for i in range(5):\n",
    "        if not all_scores[i][0].shape[-1] and not all_scores[i][1].shape[-1]:\n",
    "            all_scores[i][0] = all_scores[i][2].copy()\n",
    "            all_scores[i][1] = all_scores[i][2].copy()\n",
    "\n",
    "        if not all_scores[i][2].shape[-1] and not all_scores[i][1].shape[-1]:\n",
    "            all_scores[i][2] = all_scores[i][0].copy()\n",
    "            all_scores[i][1] = all_scores[i][0].copy()\n",
    "\n",
    "        if not all_scores[i][0].shape[-1] and not all_scores[i][2].shape[-1]:\n",
    "            all_scores[i][0] = all_scores[i][1].copy()\n",
    "            all_scores[i][2] = all_scores[i][1].copy()\n",
    "\n",
    "scores_tweak = [\n",
    "    np.concatenate([scores_fold[c] for scores_fold in all_scores if scores_fold[c].shape[-1]], 2)\n",
    "    for c in range(len(CELL_TYPES))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_mask, best_thresholds_nms, best_thresholds_conf = [], [], []\n",
    "best_scores = []\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    print(f' -> Cell type {CELL_TYPES[c]} : ')\n",
    "\n",
    "    scores_class = scores_tweak[c].mean(2) \n",
    "    idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "    best_score = scores_class[idx]\n",
    "    best_scores.append(best_score)\n",
    "\n",
    "    best_thresholds_c = (thresholds_mask[idx[0]], thresholds_nms[idx[1]], thresholds_conf[idx[2]])\n",
    "    best_thresholds_mask.append(best_thresholds_c[0])\n",
    "    best_thresholds_nms.append(best_thresholds_c[1])\n",
    "    best_thresholds_conf.append(best_thresholds_c[2])\n",
    "\n",
    "    print(f\"Best score {best_score:.4f} for thresholds (mask, nms, conf): {best_thresholds_c}\\n\")\n",
    "\n",
    "# weights = [Counter(df_oof['cell_type'])[c] for c in CELL_TYPES]\n",
    "weights = [Counter(all_cell_types)[c] for c in range(len(CELL_TYPES))]\n",
    "\n",
    "best_score = np.average(best_scores, weights=weights)\n",
    "\n",
    "print(f'CV score : {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for c in range(len(CLASSES)):\n",
    "#     print(f\"\\nClass {CLASSES[c]}\")\n",
    "#     for idx_mask, threshold_mask in enumerate(thresholds_mask):\n",
    "#         for idx_nms, threshold_nms in enumerate(thresholds_nms):\n",
    "#             print(f\"\\n-> Threshold mask = {threshold_mask} - Threshold nms = {threshold_nms}\")\n",
    "#             for s, conf in zip(np.mean(scores_tweak[c][idx_mask, idx_nms], 0) , thresholds_conf):\n",
    "#                 print(f\"Threshold conf = {conf} - score = {s:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'THRESHOLDS_MASK = {best_thresholds_mask}')\n",
    "print(f'THRESHOLDS_NMS = {best_thresholds_nms}')\n",
    "print(f'THRESHOLDS_CONF = {best_thresholds_conf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = [[], [], []]\n",
    "metadata = []\n",
    "\n",
    "for results, dataset in zip(all_results, datasets):\n",
    "    masks_pred, boxes_pred, cell_types = process_results(\n",
    "        results,\n",
    "        best_thresholds_mask,\n",
    "        best_thresholds_nms,\n",
    "        best_thresholds_conf,\n",
    "        remove_overlap=True,\n",
    "        corrupt=True\n",
    "    )\n",
    "    \n",
    "    scores, scores_per_class = evaluate(\n",
    "        masks_pred,\n",
    "        dataset,\n",
    "        cell_types\n",
    "    )\n",
    "\n",
    "    for masks, boxes, cell_type_pred, img_id, score, cell_type in zip(\n",
    "        masks_pred, boxes_pred, cell_types, dataset.df['id'].values, scores, dataset.df['cell_type'].values\n",
    "    ):\n",
    "        metadata.append({\n",
    "            'id': img_id,\n",
    "            'cell_type': cell_type,\n",
    "            'cell_type_pred': cell_type_pred,\n",
    "            'rles': [rle_encode(mask) for mask in masks],\n",
    "            'boxes': boxes.tolist(),\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "    for i, s in enumerate(scores_per_class):\n",
    "        all_scores[i] += s\n",
    "        \n",
    "#     del masks_pred, boxes_pred, cell_types\n",
    "#     gc.collect()\n",
    "\n",
    "#     break\n",
    "    \n",
    "df_preds_oof = pd.DataFrame.from_dict(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' -> IoU mAP : {df_preds_oof.score.mean():.4f}\\n')\n",
    "df_preds_oof[['cell_type', 'score']].groupby('cell_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save no thesholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.post_process import process_results_nothresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_crop(crop, size=64, shape=(520, 704)):\n",
    "    w = crop[1] - crop[0]\n",
    "    pad_l = np.floor((size - w) / 2)\n",
    "    pad_r = np.ceil((size - w) / 2)\n",
    "    \n",
    "    assert pad_l + pad_r + w == size, pad_l + pad_r + w\n",
    "    \n",
    "    h = crop[3] - crop[2]\n",
    "    pad_t = np.floor((size - h) / 2)\n",
    "    pad_b = np.ceil((size - h) / 2)\n",
    "    \n",
    "    assert pad_t + pad_b + h == size, pad_t + pad_b + h\n",
    "    \n",
    "    new_crop = np.array([crop[0] - pad_l, crop[1] + pad_r, crop[2] - pad_t, crop[3] + pad_b]).astype(int)\n",
    "    \n",
    "    if new_crop[0] < 0:\n",
    "        new_crop[1] -= new_crop[0]\n",
    "        new_crop[0] = 0\n",
    "\n",
    "    if new_crop[2] < 0:\n",
    "        new_crop[3] -= new_crop[2]\n",
    "        new_crop[2] = 0\n",
    "\n",
    "    if new_crop[1] > shape[0]:\n",
    "        new_crop[0] -= (new_crop[1] - shape[0])\n",
    "        new_crop[1] = shape[0]\n",
    "\n",
    "    if new_crop[3] > shape[1]:\n",
    "        new_crop[2] -= (new_crop[3] - shape[1])\n",
    "        new_crop[3] = shape[1]\n",
    "    \n",
    "    assert new_crop[1] - new_crop[0] == size, new_crop[1] - new_crop[0]\n",
    "    assert new_crop[3] - new_crop[2] == size, new_crop[3] - new_crop[2]\n",
    "\n",
    "    return new_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_scores = [[], [], []]\n",
    "metadata = []\n",
    "\n",
    "for fold_idx, (results, dataset) in enumerate(zip(all_results, datasets)):\n",
    "    masks_pred, boxes_pred, cell_types = process_results_nothresh(\n",
    "        results,\n",
    "        best_thresholds_mask,\n",
    "        best_thresholds_nms,\n",
    "        0.1,\n",
    "    )\n",
    "\n",
    "    for i, (mask_pred, rle_truth) in enumerate(tqdm(zip(masks_pred, dataset.encodings))):\n",
    "        data = dataset[i]\n",
    "        img = dataset[i]['img']\n",
    "        mask_truth = dataset[i]['gt_masks'].masks\n",
    "        \n",
    "        name = dataset.df['id'][i]\n",
    "        \n",
    "        rle_pred = [pycocotools.mask.encode(np.asarray(p > (0.45 * 255), order='F')) for p in mask_pred]\n",
    "\n",
    "        ious = pycocotools.mask.iou(rle_truth.tolist(), rle_pred, [0] * len(rle_pred))\n",
    "        score = iou_map(ious=[ious])\n",
    "\n",
    "#         print(ious.shape, len(rle_pred), len(rle_truth))\n",
    "        \n",
    "        for cell_idx, (mask, box) in enumerate(zip(mask_pred, boxes_pred[i])):\n",
    "            match = ious[:, cell_idx].argmax()\n",
    "            iou = ious[:, cell_idx].max()\n",
    "\n",
    "            crop = np.array([box[1], box[3] + 1, box[0], box[2] + 1]).astype(int)\n",
    "            crop = extend_crop(crop)\n",
    "\n",
    "            img_crop = img[crop[0]: crop[1], crop[2]: crop[3]]\n",
    "            pred = mask[crop[0]: crop[1], crop[2]: crop[3]]\n",
    "            others = (\n",
    "                mask_pred[[i for i in range(len(mask_pred)) if i != cell_idx], crop[0]: crop[1], crop[2]: crop[3]]\n",
    "            ).max(0)\n",
    "            truth = mask_truth[match][crop[0]: crop[1], crop[2]: crop[3]]\n",
    "\n",
    "            if PLOT:\n",
    "                plt.figure(figsize=(15, 5))\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(pred)\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(others)\n",
    "                plt.subplot(1, 3, 3)     \n",
    "                plot_sample(img_crop, truth[None])\n",
    "                plt.show()\n",
    "\n",
    "            to_save = np.concatenate([\n",
    "                img_crop[:, :, 0][None],\n",
    "                pred[None],\n",
    "                others[None],\n",
    "                truth[None]\n",
    "            ])\n",
    "\n",
    "            conf = box[4]\n",
    "            name = f\"{fold_idx}_{dataset.df['id'][i]}_{cell_idx}_{conf:.4f}\"\n",
    "#             np.save(f\"../output/cort/{name}.npy\", to_save)\n",
    "\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(EXP_FOLDERS) == 1:\n",
    "#     save_folder = EXP_FOLDERS[0]\n",
    "#     name = 'df_oof.csv'\n",
    "# else:\n",
    "#     save_folder = OUT_PATH\n",
    "#     name = 'df_oof_blend'\n",
    "\n",
    "#     for f in EXP_FOLDERS:\n",
    "#         name += f\"_{f.split('/')[-3][5:]}-{f.split('/')[-2]}\"\n",
    "#     name += \".csv\"\n",
    "\n",
    "# print(f'-> Saved results to \"{save_folder + name}\"')\n",
    "\n",
    "# df_preds_oof.to_csv(save_folder + name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(len(all_scores)):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.title(CELL_TYPES[i], size=15)\n",
    "    plt.grid(True)\n",
    "    plt.scatter(range(len(all_scores[i])), sorted(all_scores[i]), s=20)\n",
    "#     plt.ylim(0, 0.75)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('IoU mAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = df_oof.merge(df_preds_oof, on=\"id\", how=\"left\", suffixes=('', '_pred'))\n",
    "df_oof['n_cells'] = df_oof['annotation'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_oof.groupby('plate').mean()[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.violinplot(x='score', y='plate', data=df_oof.sort_values('plate'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof.groupby('cell_type').mean()[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_preds, masks_truth = [], []\n",
    "\n",
    "# for results, dataset in zip(all_results, datasets):\n",
    "#     masks_pred, boxes_pred, cell_types = process_results(\n",
    "#         results, best_thresholds_mask, best_thresholds_nms, best_thresholds_conf, remove_overlap=True\n",
    "#     )\n",
    "    \n",
    "#     masks_preds.append(masks.max(0))\n",
    "    \n",
    "#     masks_truth += [masks.masks.max(0) for masks in dataset.masks]\n",
    "\n",
    "# dice_score(np.array(masks_preds), np.array(masks_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SartoriusDataset(df_oof, transforms=pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(len(dataset)):\n",
    "    if df_oof['plate'][idx] != \"cort[density]\":\n",
    "        continue\n",
    "    \n",
    "    score = df_preds_oof['score'][idx]\n",
    "    c = df_preds_oof['cell_type'][idx]\n",
    "    \n",
    "    data = dataset[idx]\n",
    "    img = data['img']\n",
    "    \n",
    "    # truth\n",
    "    truth = data['gt_masks'].masks.copy().astype(int)\n",
    "    boxes_truth = data['gt_bboxes']\n",
    "    \n",
    "    # preds\n",
    "    rles = df_preds_oof['rles'][idx]\n",
    "    pred = np.array([rle_decode(enc, ORIG_SIZE) for enc in rles]).astype(int)\n",
    "    boxes = df_preds_oof['boxes'][idx]\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, pred, boxes, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Pred - {CELL_TYPES[c]} - iou_map={score:.3f}')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, truth, boxes_truth, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(f'Truth - {df_oof[\"cell_type\"][idx]}')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-' * 100)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(img, pred, truth, plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # new folds - fix tta\n",
    "#     LOG_PATH + \"2021-12-11/2/\",  # 1. Cascade b5 - 0.3134\n",
    "    LOG_PATH + \"2021-12-11/4/\",  # 2. Cascade rx101 - 0.3154\n",
    "#     LOG_PATH + \"2021-12-12/0/\",  # 3. Cascade r50 - 0.3133\n",
    "#     LOG_PATH + \"seb/mrcnn_resnext101_lossdecay/\",  # 11.\n",
    "#     LOG_PATH + \"seb/mrcnn_r50_lossdecay/\",  # 12.\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [3000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.75, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.95, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],  # [1500, 1000, 500],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.75, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0., 0., 0.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    config.split = \"skf\"\n",
    "    configs.append(config)\n",
    "\n",
    "#     weights.append(sorted(glob.glob(exp_folder + \"*.pt\")))\n",
    "    weights.append(sorted(glob.glob(exp_folder + \"*.pt\"))[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "results_s, all_stuff, df_oof_s = inference_single(df, configs, weights, ENSEMBLE_CONFIG, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = prepare_data(fix=False, remove_anomalies=True)\n",
    "results_s, all_stuff, df_oof_s = inference_single(df, configs, weights, ENSEMBLE_CONFIG, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(config.data_config)\n",
    "dataset_s = SartoriusDataset(df_oof_s, transforms=pipelines['val_viz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds_mask = [0.45]\n",
    "thresholds_nms = [np.round(0.05 * i, 2) for i in range(1, 10)]\n",
    "thresholds_conf = [np.round(0.05 * i, 2) for i in range(1, 18)]\n",
    "\n",
    "scores = tweak_thresholds(\n",
    "    results_s,\n",
    "    dataset_s,\n",
    "    thresholds_mask,\n",
    "    thresholds_nms,\n",
    "    thresholds_conf,\n",
    "    remove_overlap=True\n",
    ")\n",
    "\n",
    "for c in range(len(CELL_TYPES)):\n",
    "    scores_class = scores[c]\n",
    "\n",
    "    if scores_class.shape[2]:\n",
    "        scores_class = scores[c].mean(2) \n",
    "        \n",
    "        idx = np.unravel_index(np.argmax(scores_class, axis=None), scores_class.shape)\n",
    "        best_score = scores_class[idx]\n",
    "        \n",
    "        threshold_mask = thresholds_mask[idx[0]]\n",
    "        threshold_nms = thresholds_nms[idx[1]]\n",
    "        threshold_conf = thresholds_conf[idx[2]]\n",
    "\n",
    "        print(f\"Best score {best_score:.4f} for thresholds : \")\n",
    "        print(f'- Threshold mask : {threshold_mask}')\n",
    "        print(f'- Threshold nms  : {threshold_nms}')\n",
    "        print(f'- Threshold conf : {threshold_conf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_pred, boxes_pred, cell_types = process_results(\n",
    "    results_s, threshold_mask, threshold_nms, threshold_conf, remove_overlap=True, corrupt=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores_single, _ = evaluate(masks_pred, dataset_s, cell_types)\n",
    "\n",
    "print(f' -> IoU mAP : {np.mean(scores_single):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_s[idx]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "pred = masks_pred[idx].copy().astype(int)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=pred, boxes=boxes_pred[idx])\n",
    "# plot_sample(img, mask=truth)\n",
    "plt.title(f'{CELL_TYPES[cell_types[idx]]} - iou_map={np.mean(scores_single):.3f}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "data = dataset_s[idx]\n",
    "\n",
    "img = data['img']\n",
    "truth = data['gt_masks'].masks.copy().astype(int)\n",
    "boxes_truth = data['gt_bboxes']\n",
    "pred = masks_pred[idx].copy().astype(int)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=pred, boxes=boxes_pred[idx])\n",
    "# plot_sample(img, mask=truth)\n",
    "plt.title(f'{CELL_TYPES[cell_types[idx]]} - iou_map={np.mean(scores_single):.3f}')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_list, merged_bboxes, bboxes, aug_masks, masks = all_stuff\n",
    "\n",
    "bboxes = bboxes.cpu().numpy()\n",
    "merged_bboxes = merged_bboxes.cpu().numpy()\n",
    "proposals = proposal_list[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Number of proposals : {[len(prop) for prop in aug_proposals[0]]}')\n",
    "print(f'Number of merged proposals : {len(proposals)}')\n",
    "print(f'Number of merged boxes : {len(merged_bboxes)}')\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Number of detected boxes (th={0.05 * i:.2f}): {(bboxes[:, 4] > 0.05 * i).sum()}')\n",
    "    \n",
    "print()\n",
    "print(f'Number of pred masks after pp : {len(pred)}')\n",
    "print(f'Number of gt masks : {len(truth)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_sample(img, mask=None, boxes=merged_bboxes)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_hit = 0.4\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "missed = []\n",
    "for i, preds in enumerate((proposals, bboxes)):\n",
    "    max_ious = []\n",
    "    for b in boxes_truth:\n",
    "        ious = []\n",
    "        for prop in preds[preds[:, 4] > 0.]:\n",
    "            ious.append(bbox_iou(b, prop))\n",
    "\n",
    "        max_ious.append(np.max(ious))\n",
    "\n",
    "    max_ious = np.array(max_ious)\n",
    "    missed.append(boxes_truth[(max_ious < threshold_hit)])\n",
    "\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    sns.histplot(max_ious, bins=20)\n",
    "    plt.axvline(threshold_hit, c=\"salmon\")\n",
    "    t = 'proposals' if i == 0 else \"bboxes\"\n",
    "    plt.title(t + f' - missed {len(missed[-1])}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = (pred.astype(int).max(0) > 0)[..., None]\n",
    "# img_m = img * (1 - m) + 129 * m\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.imshow(img_m)\n",
    "# #         plot_sample(img * (1 - m) + 131 * m, masks.astype(int))\n",
    "# plt.axis(False)\n",
    "# plt.title(img_id)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# cv2.imwrite('test.png', img_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_preds_iou(\n",
    "    img,\n",
    "    pred,\n",
    "    truth,\n",
    "#     boxes=missed[1],\n",
    "#     boxes_2=missed[0],\n",
    "    plot_tp=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=900,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masks_comp = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged, _, picks = mask_nms(\n",
    "#     np.concatenate([pred > 0, masks_comp > 0]),\n",
    "#     np.concatenate([np.ones((len(pred), 5)), 0.1 * np.ones((len(masks_comp), 5))]),\n",
    "#     0.0\n",
    "# )\n",
    "\n",
    "# # merged = pred > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = remove_overlap_naive(merged)\n",
    "# merged = merged.astype(int)\n",
    "# for i in range(len(merged)):\n",
    "#     merged[i] *= (i + 1)\n",
    "\n",
    "# merged = merged.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_map([truth.max(0)], [merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_map([truth.max(0)], [merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_preds_iou(\n",
    "#     img,\n",
    "#     merged.astype(int),\n",
    "#     truth,\n",
    "# #     boxes=missed[1],\n",
    "# #     boxes_2=missed[0],\n",
    "#     plot_tp=True)\n",
    "\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=900,\n",
    "#     height=700,\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(masks_comp.max(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
