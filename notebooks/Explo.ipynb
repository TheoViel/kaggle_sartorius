{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.rle import *\n",
    "from utils.plots import *\n",
    "from utils.metrics import iou_map\n",
    "from utils.rle import rles_to_mask_fix\n",
    "from utils.logger import prepare_log_folder, create_logger, save_config\n",
    "\n",
    "from data.preparation import prepare_data, prepare_extra_data\n",
    "from data.dataset import SartoriusDataset\n",
    "from data.transforms import define_pipelines\n",
    "\n",
    "from training.main import k_fold\n",
    "from inference.post_process import *\n",
    "from utils.metrics import *\n",
    "from utils.torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet\n",
    "import mmdet.models\n",
    "from mmcv import Config\n",
    "\n",
    "from mmcv.utils import build_from_cfg\n",
    "from mmdet.datasets.builder import PIPELINES\n",
    "from mmdet.datasets.pipelines import Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # Images\n",
    "    use_mosaic = False\n",
    "    use_tta = False  # TODO\n",
    "    data_config = \"configs/config_aug_mosaic.py\" if use_mosaic else \"configs/config_aug.py\"\n",
    "#     data_config = \"data/config_rescale.py\"\n",
    "\n",
    "    k = 5\n",
    "    random_state = 0\n",
    "    split = \"sgkf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(remove_anomalies=True)\n",
    "# df = prepare_extra_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import prepare_data, prepare_extra_data, get_splits\n",
    "splits = get_splits(df, Config)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(splits):\n",
    "    print(f\"\\n-------------   Fold {i + 1} / {Config.k}  -------------\\n\")\n",
    "    print(Counter(df.iloc[val_idx]['cell_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['ann'].apply(lambda x: len(x['bboxes']))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.histplot(x='len', hue=\"cell_type\", data=df, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['sample_id'].unique()), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(Config.data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SartoriusDataset(df, pipelines['test_viz'], precompute_masks=False)\n",
    "dataset = SartoriusDataset(df, pipelines['val_viz'], precompute_masks=False)\n",
    "# dataset = SartoriusDataset(df, pipelines['train_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=True)\n",
    "\n",
    "df = df.sort_values('sample_id').reset_index(drop=True)\n",
    "\n",
    "dataset = SartoriusDataset(df, pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['plate'] = df['sample_id'].apply(lambda x: x.split('_')[0])\n",
    "df['plate_well'] = df['sample_id'].apply(lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['plate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df[df['plate'] == \"astros[cereb]\"].reset_index(drop=True)\n",
    "\n",
    "dataset = SartoriusDataset(df_plot, pipelines['val_viz'], precompute_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(min(10, len(df_plot))):\n",
    "    \n",
    "    data = dataset[idx]\n",
    "\n",
    "    masks = np.array([rle_decode(enc, ORIG_SIZE) for enc in df_plot['annotation'][idx]])\n",
    "\n",
    "    img = data['img']\n",
    "    boxes = data['gt_bboxes']\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, masks, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(df_plot['sample_id'][idx])\n",
    "    plt.show()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(min(10, len(df_plot))):\n",
    "    \n",
    "    data = dataset[idx]\n",
    "\n",
    "    masks = np.array([rle_decode(enc, ORIG_SIZE) for enc in df_plot['annotation'][idx]])\n",
    "\n",
    "    img = data['img']\n",
    "    boxes = data['gt_bboxes']\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plot_sample(img, masks, plotly=False)\n",
    "    plt.axis(False)\n",
    "    plt.title(df_plot['sample_id'][idx])\n",
    "    plt.show()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = {}\n",
    "\n",
    "# for idx in tqdm(range(len(dataset))):\n",
    "#     cell_type = df['cell_type'][idx]\n",
    "#     data = dataset[idx]\n",
    "#     boxes = data['gt_bboxes']\n",
    "    \n",
    "#     if cell_type == \"astro\" and len(boxes) > 300:\n",
    "#         img = data['img']\n",
    "#         plt.figure(figsize=(15, 15))\n",
    "#         plot_sample(img, data['gt_masks'])\n",
    "#         plt.axis(False)\n",
    "#         plt.show()\n",
    "        \n",
    "    \n",
    "#     try:\n",
    "#         lens[cell_type].append(len(boxes))\n",
    "#     except:\n",
    "#         lens[cell_type] = [len(boxes)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 5))\n",
    "# for i, c in enumerate(lens):\n",
    "#     plt.subplot(1, 3, i + 1)\n",
    "#     sns.histplot(lens[c])\n",
    "# #     plt.axvline(1000, c=\"salmon\")\n",
    "#     plt.title(c)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ious = {}\n",
    "\n",
    "# for idx in tqdm(range(len(dataset))):\n",
    "#     cell_type = df['cell_type'][idx]\n",
    "    \n",
    "#     data = dataset[idx]\n",
    "#     boxes = data['gt_bboxes']\n",
    "    \n",
    "#     for i, b1 in enumerate(boxes):\n",
    "#         for b2 in boxes[:i]:\n",
    "#             iou = 0 if (b1 == b2).all() else bbox_iou(b1, b2)\n",
    "#             if iou:\n",
    "#                 try:\n",
    "#                     ious[cell_type].append(iou)\n",
    "#                 except:\n",
    "#                     ious[cell_type] = [iou]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 5))\n",
    "# for i, c in enumerate(ious):\n",
    "#     plt.subplot(1, 3, i + 1)\n",
    "#     sns.histplot(ious[c])\n",
    "#     plt.axvline(0.5, c=\"salmon\")\n",
    "#     plt.title(c)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, c in enumerate(ious):\n",
    "#     print((np.array(ious[c]) > 0.5).sum(), (np.array(ious[c]) > 0.5).sum() / len(ious[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sizes_, ratios_, ns = [], [], []\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     data = dataset[i]\n",
    "# #     img = data['img']\n",
    "#     boxes = data['gt_bboxes'].astype(float)\n",
    "\n",
    "#     sizes = np.max([boxes[:, 2] - boxes[:, 0], boxes[:, 3] - boxes[:, 1]], 0)\n",
    "#     ratios = (boxes[:, 2] - boxes[:, 0]) / (boxes[:, 3] - boxes[:, 1])\n",
    "#     ratios = np.max([ratios, 1 / ratios], 0)\n",
    "#     ns.append(len(boxes))\n",
    "    \n",
    "# #     if np.max(ratios) > 10:\n",
    "#     if len(boxes) > 600:\n",
    "# #     if np.max(sizes) > 256:\n",
    "#         plt.figure(figsize=(15, 15))\n",
    "#         plot_sample(data['img'], data['gt_masks'], boxes, plotly=False)\n",
    "#         plt.axis(False)\n",
    "#         plt.show()\n",
    "        \n",
    "    \n",
    "#     sizes_.append(sizes)\n",
    "#     ratios_.append(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SartoriusDataset(df, pipelines['train_viz'], precompute_masks=False)\n",
    "# dataset = to_mosaic(Config, dataset, 'mosaic_viz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for _ in range(1):\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "    \n",
    "#     for i in range(4):\n",
    "#         plt.subplot(2, 2, i + 1)\n",
    "#         idx = np.random.choice(len(dataset))\n",
    "# #         idx = 581\n",
    "\n",
    "#         data = dataset[idx]\n",
    "#         print(data['img'].shape)\n",
    "#         plot_sample(data['img'], data['gt_masks'], data['gt_bboxes'], plotly=False)\n",
    "# #         print(data['img'].shape)\n",
    "\n",
    "#         plt.axis(False)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crop'] = df['sample_id'].apply(lambda x: x[-1])\n",
    "# df['sample_id'] = df['sample_id'].apply(lambda x: x[:-2])\n",
    "df['plate'] = df['sample_id'].apply(lambda x: x.split('_')[0])\n",
    "df['well'] = df['sample_id'].apply(lambda x: x.split('_')[1])\n",
    "df['plate_well'] = df['sample_id'].apply(lambda x: x.rsplit('_', 3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pl = pd.DataFrame({'id': os.listdir(DATA_PATH + \"train_semi_supervised/\")})\n",
    "df_pl['img_path'] = DATA_PATH + \"train_semi_supervised/\" + df_pl['id']\n",
    "df_pl['id'] = df_pl['id'].apply(lambda x: x[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pl.head()\n",
    "\n",
    "df_pl['crop'] = df_pl['id'].apply(lambda x: x[-1])\n",
    "# df['sample_id'] = df['sample_id'].apply(lambda x: x[:-2])\n",
    "df_pl['plate'] = df_pl['id'].apply(lambda x: x.split('_')[0])\n",
    "df_pl['well'] = df_pl['id'].apply(lambda x: x.split('_')[1])\n",
    "\n",
    "df_pl['plate_well'] = df_pl['plate'] + '_' + df_pl['well']\n",
    "\n",
    "# df_pl['date'] = df_pl['id'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['plate_well'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_pl['plate_well'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['elapsed_timedelta'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df[['sample_id', 'plate_time']].groupby('sample_id').agg(list)\n",
    "dfg['plate_time'] = dfg['plate_time'].apply(lambda x: np.unique(x))\n",
    "\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['sample_id'].apply(lambda x: x[:-4]) + df['sample_date'] + \"_\"+ df['plate_time'] + df['sample_id'].apply(lambda x: x[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(df['id'].values).intersection(set(df_pl['id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = pd.concat([df[['id', 'img_path']], df_pl[['id', 'img_path']]])\n",
    "df_ids['train'] = [1] * len(df) + [0] * len(df_pl)\n",
    "\n",
    "df_ids['id_nophase'] = df_ids['id'].apply(lambda x: x[:-5])\n",
    "df_ids['phase'] = df_ids['id'].apply(lambda x: x[-4:])\n",
    "\n",
    "df_ids = df_ids.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "df_ids['plate'] = df_ids['id_nophase'].apply(lambda x: x.rsplit('_', 2)[0])\n",
    "df_ids['plate_phase'] = df_ids['plate'] + \"_\"  + df_ids['phase'] \n",
    "df_ids['time'] = df_ids['id_nophase'].apply(lambda x: x.split('_', 3)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sample_id'] = df['sample_id'].apply(lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfg = df_ids.groupby('plate').agg(list)[[\"phase\", \"time\", \"train\"]].reset_index()\n",
    "dfg['len'] = dfg['phase'].apply(len)\n",
    "dfg['time'] = dfg['time'].apply(lambda x: Counter(x))\n",
    "dfg['phase'] = dfg['phase'].apply(lambda x: Counter(x))\n",
    "\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = df_ids.groupby('plate').agg(list)['img_path'].apply(len).values\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16 * len(counts) - counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df_ids.groupby('id_nophase').agg(list)[['phase', 'train']].reset_index()\n",
    "dfg['n'] = dfg['phase'].apply(len)\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(dfg['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df_ids.groupby('plate_phase').agg(list)[['train', 'time']].reset_index()\n",
    "dfg['n'] = dfg['train'].apply(len)\n",
    "dfg[dfg['n'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(dfg['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df_ids.groupby('plate').agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfg['id'].apply(len).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfg['id'].apply(len).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for plate_phase in dfg['plate_phase'].values:\n",
    "    df_plot = df_ids[df_ids['plate_phase'] == plate_phase].reset_index()\n",
    "    \n",
    "    if not np.max(df_plot['train']):\n",
    "        continue\n",
    "        \n",
    "    print(plate_phase)\n",
    "\n",
    "    for idx in range(len(df_plot)):\n",
    "        img = cv2.imread(df_plot['img_path'][idx])\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plot_sample(img) #, masks, plotly=False)\n",
    "        plt.axis(False)\n",
    "        plt.title(df_plot['id'][idx] + \" -- is train : \" + str(df_plot['train'][idx]))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader import define_loaders\n",
    "from training.optim import define_optimizer\n",
    "\n",
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = define_model(\"configs/config_cascade.py\", encoder=\"resnext101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = define_pipelines(\"configs/config_aug.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SartoriusDataset(\n",
    "    df.head(1),\n",
    "    pipelines['train'],\n",
    "    precompute_masks=False,\n",
    ")\n",
    "# train_dataset.sample_extra_data(0)\n",
    "\n",
    "test_dataset = SartoriusDataset(df, pipelines['test'], precompute_masks=False)\n",
    "# test_dataset = SartoriusDataset(df, pipelines['test_tta'], precompute_masks=False)\n",
    "\n",
    "train_loader, val_loader = define_loaders(train_dataset, test_dataset, batch_size=1, val_bs=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.torch import count_parameters\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in tqdm(train_loader):\n",
    "    results = model(**batch, return_loss=True)\n",
    "    \n",
    "    print(batch['img'].data[0].mean())\n",
    "\n",
    "    print(results)\n",
    "\n",
    "#     print(batch['img'].data[0].size())    \n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in tqdm(train_loader):\n",
    "    results = model(**batch, return_loss=True)\n",
    "    \n",
    "    print(batch['img'].data[0].mean())\n",
    "\n",
    "#     print(batch['img'].data[0].size())    \n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "#     break\n",
    "\n",
    "    print('''\\n\\n\\n''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        results = model(**batch, return_loss=False, rescale=True)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(results[0][0])):\n",
    "    print(results[0][0][c].shape)\n",
    "    print(results[0][1][1][c].shape)\n",
    "    \n",
    "    results[0][0][c] = np.concatenate([results[0][0][c], results[0][1][1][c][:, None]], -1)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[0][1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#             print(type(obj), obj.size())\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.ensemble import EnsembleModel\n",
    "from mmcv.parallel import MMDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.roi_head.bbox_head.get_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = MMDataParallel(EnsembleModel([model, model]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        for b in batch:\n",
    "            batch[b] = [batch[b]]  # no tta\n",
    "\n",
    "    #     batch['img_metas'][0].data[0][0]['scale_factor'] = np.ones(4, dtype=np.float32)\n",
    "        results = models(**batch, return_loss=False, rescale=True)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    first_epoch_eval = 0\n",
    "    compute_val_loss = False\n",
    "    verbose_eval = 5\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Images\n",
    "    fix = False\n",
    "    use_mosaic = False\n",
    "    use_tta = False  # TODO\n",
    "    # data_config = \"data/config_mosaic.py\" if use_mosaic else \"data/config.py\"\n",
    "    data_config = \"data/config.py\"\n",
    "\n",
    "    # k-fold\n",
    "    k = 5\n",
    "    random_state = 0\n",
    "    selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # Model\n",
    "    name = \"maskrcnn\"  # \"cascade\"\n",
    "    reduce_stride = False\n",
    "    pretrain = False\n",
    "    \n",
    "    if pretrain and reduce_stride:\n",
    "        model_config = f\"model_zoo/config_{name}_stride_pretrain.py\"\n",
    "    elif pretrain:\n",
    "        model_config = f\"model_zoo/config_{name}_pretrain.py\" \n",
    "    elif reduce_stride:\n",
    "        model_config = f\"model_zoo/config_{name}_stride.py\"\n",
    "    else:\n",
    "        model_config = f\"model_zoo/config_{name}.py\"\n",
    "\n",
    "    pretrained_folder = None\n",
    "    # pretrained_folder = \"../logs/2021-11-04/6/\"\n",
    "\n",
    "    # Training\n",
    "    optimizer = \"Adam\"\n",
    "    scheduler = \"plateau\" if optimizer == \"SGD\" else \"linear\"\n",
    "    weight_decay = 0.0005 if optimizer == \"SGD\" else 0\n",
    "    batch_size = 2 if reduce_stride else 2\n",
    "    val_bs = batch_size\n",
    "\n",
    "    epochs = 50\n",
    "\n",
    "    lr = 5e-4\n",
    "    warmup_prop = 0.01\n",
    "\n",
    "    use_fp16 = False  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "results = k_fold(Config, log_folder=log_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
