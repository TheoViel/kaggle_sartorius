{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to do inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import pycocotools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.preparation import sub_to_mmdet\n",
    "from data.transforms import define_pipelines\n",
    "from data.dataset import SartoriusInferenceDataset\n",
    "\n",
    "from utils.logger import Config\n",
    "from utils.rle import rle_decode\n",
    "from utils.plots import plot_sample\n",
    "\n",
    "from inference.test import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_PL = True\n",
    "FOLD = 0 if IS_PL else \"*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ENS_6\n",
    "    LOG_PATH + \"2021-12-02/7/\",  # 7. Cascade b5 - 0.3179\n",
    "    LOG_PATH + \"2021-12-03/0/\",  # 8. Cascade rx101 - 0.3189\n",
    "    LOG_PATH + \"seb/mrcnn_resnext101_aug_2021-12-06/\",  # 18.  maskrcnn rx101 - 0.3197\n",
    "    LOG_PATH + \"seb/mrcnn_resnet50_aug_2021-12-07/\",  # 21. maskrcnn r50 - 0.3175\n",
    "#     LOG_PATH + \"seb/maskrcnn_resnet50_2021-12-01/\",  # 6. maskrcnn r50 - 0.3173\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS_MASK = 0.45\n",
    "THRESHOLDS_NMS = [0.1, 0.05, 0.05]\n",
    "THRESHOLDS_CONF = [0.35, 0.4, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENSEMBLE_CONFIG = {\n",
    "    \"use_tta\": True,\n",
    "    \"num_classes\": 3,\n",
    "\n",
    "    \"rpn_nms_pre\": [3000, 2000, 1000],\n",
    "    \"rpn_iou_threshold\": [0.75, 0.75, 0.6],\n",
    "    \"rpn_score_threshold\": [0.95, 0.9, 0.95],\n",
    "    \"rpn_max_per_img\": [None, None, None],  # [1500, 1000, 500],\n",
    "\n",
    "    \"bbox_nms\": True,\n",
    "    \"rcnn_iou_threshold\": [0.75, 0.9, 0.6],\n",
    "    \"rcnn_score_threshold\": [0.2, 0.3, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PL:\n",
    "    df = pd.DataFrame({'id': os.listdir(DATA_PATH + \"train_semi_supervised/\")})\n",
    "    df['predicted'] = \"\"\n",
    "    df['img_path'] = DATA_PATH + \"train_semi_supervised/\" + df['id']\n",
    "#     df = df.head(5)\n",
    "else:\n",
    "    df = pd.read_csv(DATA_PATH + \"sample_submission.csv\")\n",
    "    df['img_path'] = DATA_PATH + \"test/\" + df['id'] + \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs, weights = [], []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "    config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "    config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "    configs.append(config)\n",
    "\n",
    "    weights.append(sorted(glob.glob(exp_folder + f\"*_{FOLD}.pt\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rles = inference(\n",
    "    df,\n",
    "    configs,\n",
    "    weights,\n",
    "    ENSEMBLE_CONFIG,\n",
    "    THRESHOLDS_MASK,\n",
    "    THRESHOLDS_NMS,\n",
    "    THRESHOLDS_CONF,\n",
    "    corrupt=not IS_PL,\n",
    "    remove_overlap=not IS_PL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = []\n",
    "pipelines = define_pipelines(config.data_config)\n",
    "dataset = SartoriusInferenceDataset(df, transforms=pipelines['test_viz'], precompute_masks=False)\n",
    "\n",
    "for idx, (rle, img_id) in enumerate(zip(rles, df['id'].values)):\n",
    "    if idx < 3:\n",
    "        img = dataset[idx]['img'][0].numpy().transpose(1, 2, 0)\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        img = img[:ORIG_SIZE[0], :ORIG_SIZE[1]]\n",
    "        \n",
    "        masks = np.array([rle_decode(enc, ORIG_SIZE) for enc in rle])\n",
    "        \n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plot_sample(img, masks.astype(int))\n",
    "        plt.axis(False)\n",
    "        plt.title(img_id)\n",
    "        plt.show()        \n",
    "    \n",
    "    for enc in rle:\n",
    "        submission.append((img_id, enc))\n",
    "        \n",
    "    if not len(rle):  # Empty\n",
    "        submission.append((image_id, \"\"))\n",
    "\n",
    "df_sub = pd.DataFrame(submission, columns=['id', 'predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = df_sub.groupby('id').agg(list).reset_index()\n",
    "masks, meta = sub_to_mmdet(df_g, 0)\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plot_sample(255 * np.ones(ORIG_SIZE, dtype=np.uint8), masks.astype(int), meta['ann']['bboxes'], width=1)\n",
    "# plt.axis(False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metas = [sub_to_mmdet(df_g, i)[1] for i in range(len(df_g))]\n",
    "meta_df = pd.DataFrame.from_dict(metas)\n",
    "meta_df.to_csv(OUT_PATH + f\"pl_ens15_{FOLD}.csv\", index=False)\n",
    "print(f' -> Saved pls to \"{OUT_PATH}pl_ens15_{FOLD}.csv\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert IS_PL\n",
    "\n",
    "for FOLD in range(0, 5):\n",
    "    configs, weights = [], []\n",
    "    for exp_folder in EXP_FOLDERS:\n",
    "        config = Config(json.load(open(exp_folder + \"config.json\", 'r')))\n",
    "        config.model_config = exp_folder + config.model_config.split('/')[-1]\n",
    "        config.data_config = exp_folder + config.data_config.split('/')[-1]\n",
    "        configs.append(config)\n",
    "\n",
    "        weights.append(sorted(glob.glob(exp_folder + f\"*_{FOLD}.pt\")))\n",
    "        \n",
    "    rles = inference(\n",
    "        df,\n",
    "        configs,\n",
    "        weights,\n",
    "        ENSEMBLE_CONFIG,\n",
    "        THRESHOLDS_MASK,\n",
    "        THRESHOLDS_NMS,\n",
    "        THRESHOLDS_CONF,\n",
    "        corrupt=not IS_PL,\n",
    "        remove_overlap=not IS_PL,\n",
    "    )\n",
    "\n",
    "    submission = []\n",
    "    for idx, (rle, img_id) in enumerate(zip(rles, df['id'].values)):\n",
    "        for enc in rle:\n",
    "            submission.append((img_id, enc))\n",
    "        if not len(rle):\n",
    "            submission.append((image_id, \"\"))\n",
    "    df_sub = pd.DataFrame(submission, columns=['id', 'predicted'])\n",
    "    df_g = df_sub.groupby('id').agg(list).reset_index()\n",
    "\n",
    "    metas = [sub_to_mmdet(df_g, i)[1] for i in range(len(df_g))]\n",
    "    meta_df = pd.DataFrame.from_dict(metas)\n",
    "    meta_df.to_csv(OUT_PATH + f\"pl_ens15_{FOLD}.csv\", index=False)\n",
    "    print(f' -> Saved pls to \"{OUT_PATH}pl_ens15_{FOLD}.csv\"\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
